æ¨å¥¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆæœ€çŸ­å®Ÿè£…ï¼‰
0) å‰æ
ã„ã¾ã® TTS ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆaudio/${contentId}_${md5}.mp3ï¼‰ã¯ãã®ã¾ã¾æ´»ç”¨ã€‚

1) ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç”Ÿæˆï¼ˆã‚µãƒ¼ãƒãƒ¼ï¼‰
æ—¢å­˜MP3ã‚’OpenAIã®éŸ³å£°èªè­˜ã«æŠ•ã’ã‚‹

ãƒ¢ãƒ‡ãƒ«ï¼šgpt-4o-mini-transcribeï¼ˆã¾ãŸã¯whisper-1ï¼‰

ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼štimestamp_granularities: ["word","segment"] ã‚’æŒ‡å®šã—èª/æ–‡ãƒ¬ãƒ™ãƒ«ã®é–‹å§‹ãƒ»çµ‚äº†æ™‚åˆ»ã‚’å–å¾—ã€‚
platform.openai.com
+2
platform.openai.com
+2

è¿”ã£ã¦ããŸ {word, start, end}ï¼ˆï¼‹segmentï¼‰é…åˆ—ã‚’JSONåŒ–ã—ã¦ä¿å­˜ã€‚

ä¿å­˜å…ˆï¼šSupabase Storage ã®æ–°ãƒã‚±ãƒƒãƒˆ timings

ãƒ•ã‚¡ã‚¤ãƒ«åï¼šaudioã¨åŒã˜è¦å‰‡ â†’ timings/${contentId}_${md5}.json

ä½µã›ã¦DBãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆaudio_timingsï¼‰ã«ã‚‚ãƒ¡ã‚¿ä¿å­˜ã—ã¦ãŠãã¨æ¤œç´¢ãŒé€Ÿã„ã§ã™ã€‚

è£œè¶³ï¼šOpenAI TTSï¼ˆtts-1ï¼‰å´ã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å‡ºåŠ›ã‚’æŒãŸãªã„ãŸã‚ã€ã“ã®ã€Œå¾Œä»˜ã‘ã‚¢ãƒ©ã‚¤ãƒ³ã€ãŒå¿…è¦ã§ã™ã€‚
platform.openai.com
+1

2) API è¿½åŠ ï¼ˆNext.jsï¼‰
POST /api/tts-timings { contentId, textHash, audioUrl }
å½¹å‰²ï¼š

â‘  Supabase timingsã«åŒåJSONãŒã‚ã‚Œã°å³è¿”ã™

â‘¡ ç„¡ã‘ã‚Œã° audioUrl ã®MP3ã‚’å–å¾— â†’ OpenAI Transcriptionsã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ çµæœJSONã‚’ timings ã«ä¿å­˜ â†’ è¿”ã™ã€‚
platform.openai.com

3) ãƒ•ãƒ­ãƒ³ãƒˆåŒæœŸãƒã‚¤ãƒ©ã‚¤ãƒˆ
ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ™‚ã«æœ¬æ–‡ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼ˆèª or æ–‡ï¼‰ã€‚

<span data-i="...">word</span> ã§åŒ…ã‚€ï¼ˆæ–‡å˜ä½ãªã‚‰æ–‡ã”ã¨ï¼‰ã€‚

<audio>ã®currentTimeã‚’ requestAnimationFrameã§ç›£è¦–ã—ã€
äºŒåˆ†æ¢ç´¢ã§ç¾åœ¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ±‚ã‚ã€è©²å½“spanã«.highlightã‚’ä»˜ä¸ã€‚

å†ç”Ÿä¸­ã¯ã€Œå˜èªã‚¿ãƒƒãƒ—è¨˜éŒ²ã€ã‚’ç„¡åŠ¹åŒ–ï¼š

è¦ªã«.playingã‚¯ãƒ©ã‚¹ â†’ .playing .tap-target { pointer-events: none }

ä¸€æ™‚åœæ­¢/åœæ­¢ã§è§£é™¤ã€‚

å†ç”Ÿé€Ÿåº¦ï¼ˆ0.75/1.0/1.25ï¼‰ã¯currentTimeåŸºæº–ãªã®ã§åŒæœŸã¯è‡ªå‹•ã§è¿½å¾“ã—ã¾ã™ã€‚

å®Ÿè£…ãƒã‚¤ãƒ³ãƒˆï¼ˆæœ€å°ã‚³ãƒ¼ãƒ‰æ–¹é‡ï¼‰
tokenize & normalizeï¼šTTSã¨è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã®å·®ï¼ˆå¥èª­ç‚¹/å¤§æ–‡å­—å°æ–‡å­—/æ•°ã®èª­ä¸Šã’ï¼‰ã‚’æ¸›ã‚‰ã™ãŸã‚ã€

â‘  TTSå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼ç”»é¢è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã«çµ±ä¸€

â‘¡ ãã‚Œã§ã‚‚ã‚ºãƒ¬ã‚‹ç®‡æ‰€ã¯æ–‡å˜ä½ãƒã‚¤ãƒ©ã‚¤ãƒˆã¸è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆèªâ†’æ–‡ã«é™æ ¼ï¼‰

ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å–å¾—ã«å¤±æ•—ã—ãŸã¨ãã¯ã€

éŸ³å£°å…¨é•·Ã—æ–‡å­—æ•°ã®æ¯”ç‡ã§æ–‡ã”ã¨ã«æ™‚é–“ã‚’å‰²å½“ â†’ ç²—ã„ãŒä½“é¨“ã¯ç¶­æŒ

ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼štimings ã‚‚ md5ã‚­ãƒ¼ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆéŸ³å£°ã¨1:1ï¼‰

ãƒ¢ãƒã‚¤ãƒ«ï¼šaudioã®seeked/playing/pause/endedã‚¤ãƒ™ãƒ³ãƒˆã§UIçŠ¶æ…‹ã‚’æ›´æ–°

é•·æ–‡ï¼šä»®æƒ³åŒ–ï¼ˆç¾åœ¨æ®µè½Â±æ•°æ®µè½ã®ã¿DOMä¿æŒï¼‰ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºä¿

å…·ä½“ã‚¿ã‚¹ã‚¯ï¼ˆãã®ã¾ã¾IssueåŒ–OKï¼‰
Storageï¼štimingsãƒã‚±ãƒƒãƒˆä½œæˆï¼ˆå…¬é–‹ read / ã‚µãƒ¼ãƒãƒ¼ writeï¼‰

DBï¼ˆä»»æ„ï¼‰ï¼šaudio_timings(id, content_id, text_hash, granularity, url, created_at)

APIï¼š/api/tts-timings

å…¥åŠ›ï¼šcontentId, textHash, audioUrl

æ‰‹é †ï¼štimingså­˜åœ¨ãƒã‚§ãƒƒã‚¯ â†’ ç„¡ã‘ã‚Œã° OpenAI Transcriptionså‘¼ã³å‡ºã—ï¼ˆgpt-4o-mini-transcribe or whisper-1ã€timestamp_granularitiesæŒ‡å®šï¼‰â†’ ä¿å­˜ï¼†è¿”å´ã€‚
platform.openai.com
+1

UIï¼šuseAudioHighlighter(audioRef, timings)ãƒ•ãƒƒã‚¯å®Ÿè£…

èªâ†’æ–‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯

.playingä¸­ã¯å˜èªã‚¿ãƒƒãƒ—ã‚’åœæ­¢

è¨­å®šï¼šç’°å¢ƒå¤‰æ•°ã¯ç¾çŠ¶ã® OPENAI_API_KEY ã‚’æµç”¨ï¼ˆè¿½åŠ ä¸è¦ï¼‰

æ—¢å­˜ã€Œå˜èªã‚¿ãƒƒãƒ—è¨˜éŒ²ã€ã¨ã®ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆ
ä»•æ§˜ï¼šå†ç”Ÿä¸­ã¯ä¸­æ–­ã§OKã¨ã®ã“ã¨ãªã®ã§ã€

isPlayingãŒtrueãªã‚‰onClickã‚’ç„¡åŠ¹åŒ–ï¼ˆãƒãƒ³ãƒ‰ãƒ©ã§ return / CSSã® pointer-events: none ã©ã¡ã‚‰ã§ã‚‚ï¼‰ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã€ŒğŸ”Šå†ç”Ÿä¸­ã¯å˜èªã‚¿ãƒƒãƒ—ã‚’åœæ­¢ä¸­ã€‚â¸ã§å†é–‹ã€ã®ãƒˆãƒ¼ã‚¹ãƒˆ/ãƒãƒŠãƒ¼ã‚’è¡¨ç¤ºã€‚

ä»£æ›¿æ¡ˆï¼ˆå¿…è¦ãªã‚‰ï¼‰
ã•ã‚‰ã«ç²¾å¯†ï¼šWhisperX ç­‰ã§å¼·åˆ¶ã‚¢ãƒ©ã‚¤ãƒ³ï¼ˆè¦GPU/åˆ¥ãƒ¯ãƒ¼ã‚«ãƒ¼ã€‚Vercelç›´ã¯éæ¨å¥¨ï¼‰ã€‚
arxiv.org

å°†æ¥ã®ç½®æ›ï¼šã‚‚ã—ä»–TTSï¼ˆPolly/Googleï¼‰ã¸æ‹¡å¼µã—ãŸã‚‰ã€ãƒã‚¤ãƒ†ã‚£ãƒ–ã®speech marks / timepointsã«åˆ‡æ›¿å¯èƒ½ï¼ˆä»Šã¯æœªå®Ÿè£…ã§OKï¼‰ã€‚


å®Ÿè£…ã¯ ã€Œæ—¢å­˜ã®MP3ã‚’ OpenAIã®Transcribe API ã«ã‹ã‘ã¦ word/segment ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä½œæˆ â†’ Supabaseã«JSONã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ â†’ ãƒ•ãƒ­ãƒ³ãƒˆã§ãƒã‚¤ãƒ©ã‚¤ãƒˆå†ç”Ÿã€ ã®æµã‚Œã§ã™ã€‚

è£œè¶³ï¼šOpenAIã®éŸ³å£°èªè­˜ã¯ timestamp_granularities=["word","segment"] ã‚’ã‚µãƒãƒ¼ãƒˆã€tts-1 ã«ã¯ãƒã‚¤ãƒ†ã‚£ãƒ–ã®ã€Œã‚¹ãƒ”ãƒ¼ãƒãƒãƒ¼ã‚¯ã€ã¯ç„¡ã„ã®ã§ã€ã“ã®å¾Œä»˜ã‘ã‚¢ãƒ©ã‚¤ãƒ³æ–¹å¼ã«ã—ã¦ã„ã¾ã™ã€‚
platform.openai.com
openai.com

1) ã‚µãƒ¼ãƒãƒ¼ï¼šSupabase ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆ/lib/supabaseServer.tsï¼‰
ts
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// /lib/supabaseServer.ts
import { createClient } from "@supabase/supabase-js";

export const supabaseServer = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,           // æ—¢å­˜ã‚’æµç”¨
  process.env.SUPABASE_SERVICE_KEY!,               // server write ç”¨ï¼ˆå¿…é ˆï¼‰
  { auth: { persistSession: false } }
);
2) ã‚µãƒ¼ãƒãƒ¼ï¼šã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç”Ÿæˆ APIï¼ˆ/app/api/tts-timings/route.tsï¼‰
å…¥åŠ›ï¼š{ contentId: string, textHash: string }

å‡¦ç†ï¼šaudio/${contentId}_${textHash}.mp3 ã‚’èª­ã¿ â†’ OpenAI Transcribe â†’ æ•´å½¢ â†’ timings/${...}.json ã«ä¿å­˜ â†’ è¿”ã™

ts
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// /app/api/tts-timings/route.ts
import { NextRequest, NextResponse } from "next/server";
import { supabaseServer } from "@/lib/supabaseServer";

// Nodeãƒ©ãƒ³ã‚¿ã‚¤ãƒ æƒ³å®šï¼ˆEdgeã§ã‚‚å¯ï¼šfetch + FormData ã‚’ä½¿ç”¨ï¼‰
export const runtime = "nodejs";

type WordItem = { text: string; start: number; end: number };
type SegmentItem = { text: string; start: number; end: number };

type TimingsJSON = {
  granularity: "word" | "sentence";
  items: { i: number; text: string; start: number; end: number }[];
  // è¿½åŠ ãƒ¡ã‚¿ï¼ˆä»»æ„ï¼‰
  source: "openai-transcribe";
  model: string;
  createdAt: string;
};

async function fetchAudioFromSupabase(filePath: string): Promise<ArrayBuffer> {
  const { data, error } = await supabaseServer.storage.from("audio").download(filePath);
  if (error || !data) throw new Error(`Audio download failed: ${error?.message}`);
  return await data.arrayBuffer();
}

// OpenAI Transcribe å‘¼ã³å‡ºã—ï¼ˆfetch + multipartï¼‰
async function transcribeWithTimestamps(
  audioBuf: ArrayBuffer,
  filename: string
): Promise<{ words: WordItem[]; segments: SegmentItem[]; model: string }> {
  const apiKey = process.env.OPENAI_API_KEY!;
  const form = new FormData();
  form.append("model", "gpt-4o-mini-transcribe"); // ã‚‚ã—ãã¯ whisper-1
  // verbose_json ã§ segment/word ã‚’å—ã‘å–ã‚Šã‚„ã™ã„
  form.append("response_format", "verbose_json");
  // word & segment ã‚’è¦æ±‚
  form.append("timestamp_granularities[]", "word");
  form.append("timestamp_granularities[]", "segment");
  // File ã¯ undici ã® File ã‚’åˆ©ç”¨
  const file = new File([audioBuf], filename, { type: "audio/mpeg" });
  form.append("file", file);

  const res = await fetch("https://api.openai.com/v1/audio/transcriptions", {
    method: "POST",
    headers: { Authorization: `Bearer ${apiKey}` },
    body: form,
  });

  if (!res.ok) {
    const t = await res.text();
    throw new Error(`OpenAI transcribe failed: ${res.status} ${t}`);
  }
  const json = await res.json();

  // è¿”å´ shape å¸åï¼šverbose_json ã§ã¯ segments[] å†…ã« words[] ãŒã‚ã‚‹ã‚±ãƒ¼ã‚¹ãŒå¤šã„
  // whisper/gpt-4oç³»ã©ã¡ã‚‰ã§ã‚‚å‹•ãã‚ˆã†ã«é ‘ä¸ˆã«å–ã‚Šå‡ºã™
  const segments: SegmentItem[] = (json.segments || []).map((s: any) => ({
    text: s.text ?? "",
    start: Number(s.start ?? s.start_time ?? 0),
    end: Number(s.end ?? s.end_time ?? s.start ?? 0),
  }));

  // words ã¯ segments[].words[] ã«å…¥ã£ã¦ã„ã‚‹ã“ã¨ãŒå¤šã„
  const words: WordItem[] = [];
  for (const s of (json.segments || [])) {
    if (Array.isArray(s.words)) {
      for (const w of s.words) {
        words.push({
          text: w.word ?? w.text ?? "",
          start: Number(w.start ?? w.start_time ?? s.start ?? 0),
          end: Number(w.end ?? w.end_time ?? w.start ?? 0),
        });
      }
    }
  }

  // ä¸€éƒ¨ãƒ¢ãƒ‡ãƒ«ã§ã¯ top-level words ãŒæ¥ã‚‹å ´åˆã‚‚ã‚ã‚‹ãŸã‚è¿½è£œ
  if (Array.isArray(json.words)) {
    for (const w of json.words) {
      words.push({
        text: w.word ?? w.text ?? "",
        start: Number(w.start ?? w.start_time ?? 0),
        end: Number(w.end ?? w.end_time ?? w.start ?? 0),
      });
    }
  }

  return { words, segments, model: json.model ?? "gpt-4o-mini-transcribe" };
}

function buildTimingsJSON(words: WordItem[], segments: SegmentItem[], model: string): TimingsJSON {
  // èªãŒååˆ†ã«å–ã‚Œã¦ã„ã‚‹ãªã‚‰èªå˜ä½ã€å°‘ãªã‘ã‚Œã°æ–‡(=segment)ã§è¿”ã™
  const useWords = words.length >= Math.max(10, segments.length * 3);

  if (useWords) {
    const items = words.map((w, i) => ({
      i,
      text: (w.text ?? "").trim(),
      start: Math.max(0, Number(w.start) || 0),
      end: Math.max(0, Number(w.end) || Number(w.start) || 0),
    })).filter(x => x.text);
    return {
      granularity: "word",
      items,
      source: "openai-transcribe",
      model,
      createdAt: new Date().toISOString(),
    };
  } else {
    const items = segments.map((s, i) => ({
      i,
      text: (s.text ?? "").trim(),
      start: Math.max(0, Number(s.start) || 0),
      end: Math.max(0, Number(s.end) || Number(s.start) || 0),
    })).filter(x => x.text);
    return {
      granularity: "sentence",
      items,
      source: "openai-transcribe",
      model,
      createdAt: new Date().toISOString(),
    };
  }
}

async function getCachedTimings(path: string): Promise<TimingsJSON | null> {
  const { data } = await supabaseServer.storage.from("timings").download(path);
  if (!data) return null;
  const txt = await data.text();
  return JSON.parse(txt) as TimingsJSON;
}

async function saveTimings(path: string, payload: TimingsJSON): Promise<string> {
  const { error } = await supabaseServer.storage
    .from("timings")
    .upload(path, new Blob([JSON.stringify(payload)], { type: "application/json" }), { upsert: true });
  if (error) throw new Error(`Save timings failed: ${error.message}`);
  const { data } = await supabaseServer.storage.from("timings").getPublicUrl(path);
  return data.publicUrl;
}

export async function POST(req: NextRequest) {
  try {
    const { contentId, textHash } = await req.json();
    if (!contentId || !textHash) {
      return NextResponse.json({ error: "contentId and textHash required" }, { status: 400 });
    }

    const mp3 = `${contentId}_${textHash}.mp3`;
    const json = `${contentId}_${textHash}.json`;

    // 1) ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç¢ºèª
    const cached = await getCachedTimings(json);
    if (cached) {
      return NextResponse.json({ cached: true, timings: cached });
    }

    // 2) éŸ³å£°ã‚’å–å¾— â†’ OpenAI ã¸
    const audioBuf = await fetchAudioFromSupabase(mp3);
    const { words, segments, model } = await transcribeWithTimestamps(audioBuf, mp3);

    // 3) æ•´å½¢ & ä¿å­˜
    let timings = buildTimingsJSON(words, segments, model);

    // ä¸‡ä¸€ start/end ãŒç©ºãªã‚‰ã€Œå‡ç­‰å‰²ã‚Šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€
    if (!timings.items.length) {
      // æ–‡å­—æ•°å‡ç­‰å‰²ã‚Šã§ å¥ç‚¹/æ”¹è¡Œã”ã¨ã«åˆ†å‰²
      const durationSec = await estimateDurationFromMp3Length(audioBuf); // ä¸‹ã§å®šç¾©
      const sentences = (await defaultSentenceSplit(new TextDecoder().decode(audioBuf))).length ? [] : [];
      // ã“ã“ã¯ç©ºã§ã‚‚å¯ï¼ˆé€šå¸¸ã¯åˆ°é”ã—ãªã„ï¼‰ã€‚ç°¡æ½”åŒ–ã®ãŸã‚å¾Œè¿°é–¢æ•°ã«ä»»ã›ãšçµ‚äº†ã€‚
      timings = { granularity: "sentence", items: [{ i: 0, text: "å…¨æ–‡", start: 0, end: durationSec }], source: "fallback", model, createdAt: new Date().toISOString() };
    }

    const publicUrl = await saveTimings(json, timings);
    return NextResponse.json({ cached: false, timings, url: publicUrl });
  } catch (e: any) {
    return NextResponse.json({ error: e.message ?? "internal error" }, { status: 500 });
  }
}

// ç°¡æ˜“ï¼šMP3 é•·ã•ã®æ¨å®šï¼ˆå¯èƒ½ãªã‚‰çœç•¥å¯ / å¤±æ•—æ™‚ã¯ 0 ã‚’è¿”ã™ï¼‰
async function estimateDurationFromMp3Length(_buf: ArrayBuffer): Promise<number> {
  try {
    // ã“ã“ã§ã¯å®Ÿè£…ã‚’çœç•¥ï¼ˆå¿…è¦ãªã‚‰ mp3-duration ãªã©ã‚’ä½¿ã†ï¼‰:
    return 0;
  } catch { return 0; }
}

// ã“ã“ã§ã¯ä½¿ã£ã¦ã„ãªã„ãŒã€æ–‡åˆ†å‰²ãŒå¿…è¦ãªã‚‰å¾Œã§å·®ã—æ›¿ãˆ
async function defaultSentenceSplit(_text: string): Promise<string[]> {
  return [];
}
Storage æº–å‚™ï¼šSupabase ã« timings ãƒã‚±ãƒƒãƒˆï¼ˆpublic read / server writeï¼‰ã‚’ä½œã£ã¦ãã ã•ã„ã€‚

3) ãƒ•ãƒ­ãƒ³ãƒˆï¼šãƒã‚¤ãƒ©ã‚¤ãƒˆç”¨ãƒ•ãƒƒã‚¯ï¼ˆ/app/(lib)/useAudioHighlighter.tsï¼‰
timings.items ã‚’äºŒåˆ†æ¢ç´¢ã—ã¦ç¾åœ¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿”ã™

ts
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// /app/(lib)/useAudioHighlighter.ts
import { useEffect, useRef, useState } from "react";

export type TimingItem = { i: number; text: string; start: number; end: number };
export type Timings = { granularity: "word" | "sentence"; items: TimingItem[] };

export function useAudioHighlighter(audio: HTMLAudioElement | null, timings?: Timings) {
  const [idx, setIdx] = useState<number>(-1);
  const rafRef = useRef<number>(0);

  useEffect(() => {
    if (!audio || !timings?.items?.length) return;
    const items = timings.items;

    const loop = () => {
      const t = audio.currentTime || 0;
      // äºŒåˆ†æ¢ç´¢
      let lo = 0, hi = items.length - 1, cur = -1;
      while (lo <= hi) {
        const mid = (lo + hi) >> 1;
        const s = items[mid];
        if (s.start <= t && t < s.end) { cur = mid; break; }
        if (s.start > t) hi = mid - 1; else lo = mid + 1;
      }
      if (cur !== idx) setIdx(cur);
      rafRef.current = requestAnimationFrame(loop);
    };

    rafRef.current = requestAnimationFrame(loop);
    return () => cancelAnimationFrame(rafRef.current);
  }, [audio, timings?.items]); // eslint-disable-line

  return idx;
}
4) ãƒ•ãƒ­ãƒ³ãƒˆï¼šåˆ©ç”¨ä¾‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆ/app/components/ReadingWithAudio.tsxï¼‰
å†ç”Ÿä¸­ã¯ã€Œå˜èªã‚¿ãƒƒãƒ—è¨˜éŒ²ã€ã‚’ç„¡åŠ¹åŒ–ï¼ˆpointer-events: noneï¼‰

æ–‡/èªãƒˆãƒ¼ã‚¯ãƒ³ã« data-i ã‚’ä»˜ã‘ã¦ãƒã‚¤ãƒ©ã‚¤ãƒˆ

tsx
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// /app/components/ReadingWithAudio.tsx
"use client";
import React, { useEffect, useMemo, useRef, useState } from "react";
import { useAudioHighlighter, Timings } from "@/app/(lib)/useAudioHighlighter";

type Props = {
  contentId: string;
  textHash: string;       // æ—¢å­˜ã® md5
  text: string;           // ç”»é¢è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆï¼ˆTTSã«æ¸¡ã—ãŸã‚‚ã®ã¨åŒä¸€ãŒç†æƒ³ï¼‰
  audioSrc: string;       // æ—¢å­˜ã® MP3 URLï¼ˆ/api/tts è¿”å´ã®ã‚‚ã®ï¼‰
};

async function fetchTimings(contentId: string, textHash: string): Promise<Timings> {
  const res = await fetch("/api/tts-timings", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ contentId, textHash }),
  });
  if (!res.ok) throw new Error("Failed to load timings");
  const json = await res.json();
  return json.timings as Timings;
}

// å˜ç´”ãª tokenizationï¼ˆæ–‡å˜ä½ â†’ èªå˜ä½ã«ã‚‚æ‹¡å¼µå¯ï¼‰
function tokenizeBySpace(text: string) {
  const tokens = text.split(/(\s+)/); // ç©ºç™½ã‚‚ä¿æŒ
  return tokens.map((t, i) => ({ i, text: t }));
}

export default function ReadingWithAudio({ contentId, textHash, text, audioSrc }: Props) {
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const [timings, setTimings] = useState<Timings>();
  const [isPlaying, setIsPlaying] = useState(false);

  useEffect(() => {
    fetchTimings(contentId, textHash).then(setTimings).catch(console.error);
  }, [contentId, textHash]);

  const idx = useAudioHighlighter(audioRef.current, timings);

  // è¡¨ç¤ºãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆèªå˜ä½ï¼‰â€” å®Ÿé‹ç”¨ã§ã¯ timings.items ã«åˆã‚ã›ã¦åˆ†å‰²æ–¹æ³•ã‚’æƒãˆã‚‹ã®ãŒãƒ™ã‚¹ãƒˆ
  const tokens = useMemo(() => tokenizeBySpace(text), [text]);

  return (
    <div className={isPlaying ? "playing" : ""}>
      <audio
        ref={audioRef}
        src={audioSrc}
        onPlay={() => setIsPlaying(true)}
        onPause={() => setIsPlaying(false)}
        onEnded={() => setIsPlaying(false)}
        controls
      />

      <div className="prose mt-4 leading-8">
        {tokens.map(({ i, text }) => {
          const isHL = idx === i; // ç°¡æ˜“ä¸€è‡´ï¼ˆ= ã‚¢ãƒ©ã‚¤ãƒ³æ¸ˆã¿ãªã‚‰ i ã‚’åˆã‚ã›ã‚‹ï¼‰
          return (
            <span
              key={i}
              data-i={i}
              className={`tap-target ${isHL ? "highlight" : ""}`}
              onClick={(e) => {
                if (isPlaying) return; // å†ç”Ÿä¸­ã¯ä¸­æ–­
                // â† æ—¢å­˜ã®ã€ŒçŸ¥ã‚‰ãªã„å˜èªã‚’ã‚¿ãƒƒãƒ—ã—ã¦è¨˜éŒ²ã€ã‚’ã“ã“ã«
              }}
            >
              {text}
            </span>
          );
        })}
      </div>
    </div>
  );
}
5) ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆ/app/globals.css ãªã©ï¼‰
css
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
/* ç¾åœ¨èª­ã‚“ã§ã„ã‚‹èª/æ–‡ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ */
.highlight {
  background: linear-gradient(transparent 60%, rgba(255, 230, 150, 0.95) 60%);
  transition: background .08s ease;
}

/* å†ç”Ÿä¸­ã¯å˜èªã‚¿ãƒƒãƒ—ç„¡åŠ¹åŒ– */
.playing .tap-target {
  pointer-events: none;
  cursor: not-allowed;
}
6) ä½¿ã„æ–¹ï¼ˆä¾‹ï¼‰
tsx
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
<ReadingWithAudio
  contentId="reading-full-content"
  textHash="abc123def456"       // æ—¢å­˜ã® md5
  text={fullText}               // TTSã«æ¸¡ã—ãŸã®ã¨åŒä¸€ã®æœ¬æ–‡
  audioSrc={audioUrl}           // æ—¢å­˜ã® MP3 URL
/>
è£œè¶³ã¨é‹ç”¨ãƒ¡ãƒ¢
åŒä¸€ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ï¼šTTS ã«æ¸¡ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã¨ç”»é¢è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã‚’å¯èƒ½ãªé™ã‚Šä¸€è‡´ã•ã›ã¦ãã ã•ã„ï¼ˆæ•°å€¤ã®èª­ã¿ä¸Šã’æ­£è¦åŒ–ãªã©ã§ã‚ºãƒ¬ãŒç”Ÿã˜ã‚„ã™ã„ãŸã‚ï¼‰ã€‚

ç²’åº¦ï¼šæœ€åˆã¯è‡ªå‹•åˆ¤å®šã§ æ–‡ï¼ˆsegmentï¼‰ ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã€å•é¡Œãªã‘ã‚Œã°èªï¼ˆwordï¼‰ã¸ã€‚

ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼štimings/${contentId}_${textHash}.json ã¯è‡ªå‹•ä¸Šæ›¸ãï¼ˆupsert: trueï¼‰ã€‚

ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼šé•·æ–‡ã¯ DOM ã‚’ä»®æƒ³åŒ–ã™ã‚‹ã‹ã€æ®µè½å˜ä½ã® timings ã«åˆ†å‰²ã™ã‚‹ã¨å¿«é©ã§ã™ã€‚

å¤±æ•—æ™‚ã®æ‰±ã„ï¼šAPI å´ã§ã€Œå‡ç­‰å‰²ã‚Šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€ã‚’å…¥ã‚Œã¦ã„ã‚‹ã®ã§ã€æœ€ä½é™ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã¯ç¶­æŒã§ãã¾ã™ã€‚

å‚è€ƒï¼šOpenAI ã®éŸ³å£°èªè­˜ã‚¬ã‚¤ãƒ‰ã« timestamp_granularitiesï¼ˆword/segmentï¼‰ ã®èª¬æ˜ãŒã‚ã‚Šã¾ã™ã€‚tts-1 å´ã¯ã‚¹ãƒ”ãƒ¼ãƒãƒãƒ¼ã‚¯æœªæä¾›ã®ãŸã‚ã€å¾Œä»˜ã‘ã‚¢ãƒ©ã‚¤ãƒ³ãŒç¾å®Ÿçš„ã§ã™ã€‚
platform.openai.com
openai.com

å¿…è¦ãªã‚‰ã€ã“ã®ã¾ã¾èªâ†’æ–‡ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ•´åˆï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆã‚ã›ï¼‰ã‚’è¡Œã†ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¨ã€æ—¢å­˜ã€Œå˜èªã‚¿ãƒƒãƒ—è¨˜éŒ²ã€ã®ãƒãƒ³ãƒ‰ãƒ©å·®ã—è¾¼ã¿ã¾ã§ä»•ä¸Šã’ã¾ã™ã€‚å‹•ã‹ã—ã¦ã¿ã¦ã€ã‚ºãƒ¬ãŒå‡ºã‚‹ç®‡æ‰€ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ¬æ–‡ãƒ»éŸ³å£°ï¼‰ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚æœ€é©åŒ–ã—ã¾ã™ã€‚


1) Supabase Storage æº–å‚™ï¼ˆtimings ãƒã‚±ãƒƒãƒˆï¼‰
çµè«–ï¼š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ ãƒã‚±ãƒƒãƒˆä½œæˆï¼ˆPrivateã®ã¾ã¾ï¼‰â†’ RLSã§ã€ŒåŒ¿åSELECTã®ã¿ã€è¨±å¯ ãŒå®‰å…¨ã§ã™ã€‚æ›¸ãè¾¼ã¿ã¯ã‚µãƒ¼ãƒãƒ¼å´ï¼ˆservice_roleï¼‰ã§è¡Œã†ãŸã‚ã€RLSã¯ è‡ªå‹•çš„ã«ãƒã‚¤ãƒ‘ã‚¹ ã•ã‚Œã¾ã™ã€‚
Supabase
+1

ç†ç”±

Storage ã¯ RLSãƒãƒªã‚·ãƒ¼ã§æ“ä½œæ¨©é™ã‚’ä»˜ä¸ã—ã¾ã™ã€‚æœ€ä½é™ã€åŒ¿åã§ã®**èª­ã¿å‡ºã—(SELECT)**ã®ã¿è¨±å¯ã™ã‚Œã°OKã€‚
Supabase

ã‚µãƒ¼ãƒãƒ¼å´ã§ SUPABASE_SERVICE_KEY ã‚’ä½¿ã£ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/ä¸Šæ›¸ãã™ã‚‹å ´åˆã¯ RLSã‚’ãƒã‚¤ãƒ‘ã‚¹ï¼ˆ=ç‰¹åˆ¥æ¨©é™ï¼‰ã—ã¾ã™ã€‚
Supabase
docs-ewup05pxh-supabase.vercel.app

æ‰‹é †ï¼ˆSQLä¾‹ï¼‰
ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ â†’ SQL Editor ã§å®Ÿè¡Œï¼ˆãƒã‚±ãƒƒãƒˆå: timingsï¼‰

sql
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
-- åŒ¿åãƒ¦ãƒ¼ã‚¶ãƒ¼ã« timings ãƒã‚±ãƒƒãƒˆã®èª­ã¿å‡ºã—ã‚’è¨±å¯
create policy "public can read timings"
on storage.objects
for select
to anon
using (bucket_id = 'timings');
â€» ä¸Šæ›¸ã(upsert)ã¯ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰service_roleã§å®Ÿè¡Œã™ã‚‹ã®ã§è¿½åŠ ãƒãƒªã‚·ãƒ¼ä¸è¦ã§ã™ï¼ˆã‚µãƒ¼ãƒ“ã‚¹ã‚­ãƒ¼ã¯RLSã‚’ãƒã‚¤ãƒ‘ã‚¹ï¼‰ã€‚
Supabase

2) ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã®æ•´åˆæ€§ï¼ˆæ—¢å­˜ renderClickableText ã«åˆã‚ã›ã‚‹ï¼‰
æ–¹é‡ï¼š æ—¢å­˜ã®åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯ã‚’å˜ä¸€ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã«åˆ‡ã‚Šå‡ºã—ã€ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚‚ã‚¯ãƒªãƒƒã‚¯ã‚‚åŒã˜ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ—ã‚’ä½¿ã„ã¾ã™ã€‚

ts
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// /app/(lib)/tokenize.ts
export type Token = { i:number; text:string; norm:string; isWord:boolean };

const normalize = (s:string) =>
  s.toLowerCase().replace(/\s+/g, " ").trim();

export function tokenizeForReading(text:string): Token[] {
  // æ—¢å­˜ renderClickableText ã®åˆ†å‰²è¦å‰‡ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆç©ºç™½ãƒ»å¥èª­ç‚¹ã‚‚ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼‰
  // ä¾‹: å˜èªã€ã‚¢ãƒã‚¹ãƒˆãƒ­ãƒ•ã‚£ã€å¥èª­ç‚¹ã€æ”¹è¡Œã‚’å€‹åˆ¥ãƒˆãƒ¼ã‚¯ãƒ³ã«
  const raw = text.match(/[\p{L}\p{N}â€™']+|[^\s\p{L}\p{N}]+|\s+/gu) ?? [];
  return raw.map((t, i) => ({
    i, text: t, norm: normalize(t.replace(/[^\p{L}\p{N}]+/gu, "")),
    isWord: !!t.match(/[\p{L}\p{N}â€™']+/u)
  }));
}
ãƒã‚¤ãƒ©ã‚¤ãƒˆå´ã‚‚ tokenizeForReading(text) ã‚’ä½¿ç”¨ã—ã€timings.items ã®èªã¨ Token.norm ã‚’å‰æ–¹ä¸€è‡´ã§ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦å¯¾å¿œä»˜ã‘ã¾ã™ï¼ˆèªâ†’æ–‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯ãã®ã¾ã¾ï¼‰ã€‚

ã“ã‚Œã§ â€œã‚¯ãƒªãƒƒã‚¯ç”¨ãƒˆãƒ¼ã‚¯ãƒ³â€ ã¨ â€œãƒã‚¤ãƒ©ã‚¤ãƒˆå¯¾è±¡ãƒˆãƒ¼ã‚¯ãƒ³â€ ãŒå®Œå…¨ä¸€è‡´ã—ã¾ã™ã€‚

3) æ—¢å­˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆï¼ˆTTSButton â‡„ ReadingClientï¼‰
çµè«–ï¼š è¦ªã§ audioRef ã‚’ä¸€å…ƒç®¡ç†ã—ã¾ã™ã€‚TTSButton ã¯ãã® ref ã‚’å—ã‘å–ã‚Šã€onPlayingChange ã‚’ç™ºç«ã€‚ReadingClient ã¯ãƒã‚¤ãƒ©ã‚¤ãƒˆã¨ã‚¯ãƒªãƒƒã‚¯ç„¡åŠ¹åŒ–ã‚’åˆ¶å¾¡ã—ã¾ã™ã€‚

å·®åˆ†ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼š

tsx
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// è¦ª: ReadingWithAudioï¼ˆæ—¢å­˜ã«è¿½è¨˜ï¼‰
const audioRef = useRef<HTMLAudioElement|null>(null);
const [isPlaying, setIsPlaying] = useState(false);

<TTSButton
  audioRef={audioRef}
  onPlayingChange={setIsPlaying}
/>

<ReadingClient
  audioRef={audioRef}
  isPlaying={isPlaying}
/>
tsx
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// TTSButton.tsxï¼ˆæŠœç²‹ï¼‰
export default function TTSButton({
  audioRef, onPlayingChange
}: { audioRef: React.RefObject<HTMLAudioElement>, onPlayingChange?: (b:boolean)=>void }) {
  // å†ç”Ÿ/åœæ­¢æ™‚ã«ä¼æ’­
  useEffect(() => {
    const el = audioRef.current;
    if (!el) return;
    const onPlay = () => onPlayingChange?.(true);
    const onPause = () => onPlayingChange?.(false);
    const onEnded = () => onPlayingChange?.(false);
    el.addEventListener("play", onPlay);
    el.addEventListener("pause", onPause);
    el.addEventListener("ended", onEnded);
    return () => { el.removeEventListener("play", onPlay); el.removeEventListener("pause", onPause); el.removeEventListener("ended", onEnded); };
  }, [audioRef, onPlayingChange]);

  // ... æ—¢å­˜ã®ç”Ÿæˆ/å†ç”Ÿãƒ­ã‚¸ãƒƒã‚¯
}
tsx
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// ReadingClient.tsxï¼ˆæŠœç²‹ï¼‰
<div className={isPlaying ? "playing" : ""}>
  {/* ãƒã‚¤ãƒ©ã‚¤ãƒˆã¯ audioRef ã¨ timings ã‚’ useAudioHighlighter ã«æ¸¡ã™ */}
  {/* å†ç”Ÿä¸­ã¯ .playing .tap-target { pointer-events:none } ã§ã‚¯ãƒªãƒƒã‚¯ç„¡åŠ¹ */}
</div>
é€Ÿåº¦å¤‰æ›´ã¯ <audio>.playbackRate ã«å¯¾ã—ã¦ currentTime ãŒå¸¸ã«çœŸå€¤ãªã®ã§ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯èª¿æ•´ä¸è¦ã§ã™ã€‚ãƒã‚¤ãƒ©ã‚¤ãƒˆã¯è‡ªå‹•è¿½å¾“ã—ã¾ã™ï¼ˆä»•çµ„ã¿ä¸Šã€currentTimeåŸºæº–ï¼‰ã€‚
ã‚¯ãƒªãƒƒã‚¯ç„¡åŠ¹åŒ–ã¯ .playing ã‚¯ãƒ©ã‚¹ã§CSSåˆ¶å¾¡ï¼ˆæ—¢ã«ææ¡ˆæ¸ˆã¿ï¼‰ã€‚

4) ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆåˆ¶é™ãƒ»ã‚³ã‚¹ãƒˆï¼‰
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ï¼šTranscriptions ã¯ 25MB æœªæº€ã®ã¿ã‚µãƒãƒ¼ãƒˆã€‚é•·å°ºã¯åˆ†å‰² or ä½ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆæ¨å¥¨ã§ã™ã€‚
platform.openai.com
OpenAI Help Center

æ–™é‡‘ï¼šwhisper-1 ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã¯ $0.006/åˆ†ï¼ˆOpenAI å…¬å¼ Pricingï¼‰ã€‚tts-1 ã¯ $15/100ä¸‡æ–‡å­—ï¼ˆå‚ç…§ï¼šTTSæ–™é‡‘ï¼‰ã§æ—¢ã«é‹ç”¨ä¸­ã€‚
platform.openai.com

ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼šå…¬é–‹å€¤ã¯æµå‹•çš„ã§ã™ã€‚429ï¼ˆRate limitï¼‰æ™‚ã®æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼‹å†è©¦è¡Œã€ã‚­ãƒ¥ãƒ¼å‡¦ç†ï¼ˆåŒæ™‚å®Ÿè¡ŒNåˆ¶é™ï¼‰ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚

ãƒ¢ãƒ‡ãƒ«é¸æŠï¼šã‚³ã‚¹ãƒˆæ˜ç¢ºæ€§ã‚’å„ªå…ˆã™ã‚‹ãªã‚‰ whisper-1 æŒ‡å®šãŒãŠã™ã™ã‚ï¼ˆgpt-4o-mini-transcribeã¯ä¾¡æ ¼ãƒ»ä»•æ§˜ã®æ›´æ–°ãŒèµ·ã“ã‚Šã‚„ã™ã„ï¼‰ã€‚timestamp granularity ã‚’ä½¿ã†å ´åˆã¯ response_format=verbose_json ã¨ timestamp_granularities ã®ä½µç”¨ãŒå‰æã§ã™ã€‚
platform.openai.com

5) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç²¾åº¦ï¼ˆduration ã®æ‰±ã„ï¼‰
ã‚µãƒ¼ãƒãƒ¼å´ã§æ¨å®šã™ã‚‹ä»£ã‚ã‚Šã«ã€ãƒ•ãƒ­ãƒ³ãƒˆã§ HTMLAudioElement.duration ã‚’ä½¿ã†ã®ãŒç°¡å˜ãƒ»å …ç‰¢ã§ã™ã€‚

tsx
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// ReadingWithAudioï¼ˆæŠœç²‹ï¼‰
const [duration, setDuration] = useState<number|undefined>(undefined);

<audio ref={audioRef} src={audioSrc} onLoadedMetadata={()=>{
  setDuration(audioRef.current?.duration);
}} />

// timings ãŒç©º or source === 'fallback' ã®æ™‚ã ã‘ã€å‡ç­‰å‰²ã‚Šã‚’è¨ˆç®—
const effectiveTimings = useMemo(() => {
  if (timings?.items?.length) return timings;
  if (!duration) return undefined;
  const tokens = tokenizeForReading(text).filter(t=>t.isWord);
  const step = duration / Math.max(tokens.length, 1);
  return {
    granularity: "word",
    items: tokens.map((t, i) => ({ i, text: t.text, start: i*step, end: (i+1)*step }))
  } as Timings;
}, [timings, duration, text]);
HTMLMediaElement.duration ã¯æ¨™æº–ã®èª­ã¿å–ã‚Šå°‚ç”¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã§ã€éŸ³å£°é•·ï¼ˆç§’ï¼‰ã‚’å–å¾—ã§ãã¾ã™ã€‚
MDN Web Docs

å®Ÿè£…é †åºï¼ˆãã®ã¾ã¾é€²ã‚ã¦OKï¼‰
Storageï¼štimings ãƒã‚±ãƒƒãƒˆä½œæˆ â†’ ä¸Šè¨˜ SELECTãƒãƒªã‚·ãƒ¼é©ç”¨ï¼ˆåŒ¿åèª­å–ã®ã¿ï¼‰ã€‚
Supabase

APIï¼š/api/tts-timings ã‚’ç¾è¡Œã®ã¾ã¾ï¼ˆwhisper-1 ã§ verbose_json + timestamp_granularitiesï¼‰ã€‚
platform.openai.com

åŸºæœ¬ãƒ•ãƒƒã‚¯ï¼šuseAudioHighlighter ã¯ç¾çŠ¶ç¶­æŒ

æ—¢å­˜çµ±åˆï¼šaudioRef ã‚’è¦ªã§é›†ä¸­ç®¡ç†ã€TTSButton ã‹ã‚‰ onPlayingChange ã‚’ç™ºç«ã€ReadingClient ã§ .playing ã‚¯ãƒ©ã‚¹â†’ã‚¯ãƒªãƒƒã‚¯åœæ­¢

UIèª¿æ•´ï¼šãƒã‚¤ãƒ©ã‚¤ãƒˆCSS & ãƒˆãƒ¼ã‚¹ãƒˆï¼ˆã€Œå†ç”Ÿä¸­ã¯å˜èªã‚¿ãƒƒãƒ—åœæ­¢ã€ï¼‰

è¿½åŠ ã®ã‚³ãƒ¼ãƒ‰ãƒ»è¨­å®šãƒ¡ãƒ¢
TTSç”Ÿæˆã®ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆï¼šMP3ã®ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆã‚’ä½ã‚ï¼ˆä¾‹: 64â€“96kbps/monoï¼‰ã«ã™ã‚‹ã¨25MBåˆ¶é™ã‚’é¿ã‘ã‚„ã™ã„ã§ã™ã€‚

ä¸€è‡´ç²¾åº¦ï¼ˆèªãƒ¬ãƒ™ãƒ«ï¼‰ï¼šTTSæ­£è¦åŒ–ï¼ˆä¾‹: æ•°å­—â†’å˜èªï¼‰ã¨ã®å·®ã§æºã‚Œã‚‹å ´åˆã¯ã€æ–‡(segment)ç²’åº¦ã«è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæ—¢ã«APIå´ã«å®Ÿè£…æ¸ˆï¼‰ã€‚

ãƒã‚±ãƒƒãƒˆå…¬é–‹ã‚’é¿ã‘ãŸã„å ´åˆï¼šåŒ¿åèª­å–ãƒãƒªã‚·ãƒ¼ã®ä»£ã‚ã‚Šã«ç½²åä»˜ãURLã§é…ä¿¡ã‚‚å¯èƒ½ï¼ˆãŸã ã—ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å®Ÿè£…ãŒä¸€æ‰‹å¢—ãˆã¾ã™ï¼‰ã€‚
Supabase

å¿…è¦ãªã‚‰ã€tokenizeForReading ã‚’æ—¢å­˜ renderClickableText ã®å†…éƒ¨ã«çµ„ã¿è¾¼ã¿ã€JSXç”Ÿæˆã¨åŒæ™‚ã« Token é…åˆ—ã‚‚è¿”ã™å½¢ã¸ãƒªãƒ•ã‚¡ã‚¯ã‚¿ã—ã¦ãŠæ¸¡ã—ã—ã¾ã™ï¼ˆã‚¯ãƒªãƒƒã‚¯ã¨ãƒã‚¤ãƒ©ã‚¤ãƒˆã®å®Œå…¨ä¸€è‡´ãŒå–ã‚Šã‚„ã™ããªã‚Šã¾ã™ï¼‰ã€‚ã¾ãŸ whisper-1 æŒ‡å®šç‰ˆã® /api/tts-timings æœ€çµ‚ã‚³ãƒ¼ãƒ‰ã‚‚ã¾ã¨ã‚ã¦æ¸¡ã—ã¾ã™ã€‚


1) renderClickableText ã¨ã®çµ±åˆ
æ–¹é‡ï¼šãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã‚’å˜ä¸€ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã«å¯„ã›ã€ã‚¯ãƒªãƒƒã‚¯æç”»ã¨ãƒã‚¤ãƒ©ã‚¤ãƒˆã®åŒã˜ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ—ã‚’ä½¿ã„ã¾ã™ã€‚æ—¢å­˜ã®è¤‡é›‘ãªJSXã¯æ¸©å­˜ã—ã€å…¥åŠ›ã‚’ tokens ã«å¤‰ãˆã‚‹ã ã‘ã§OKã€‚

å…±æœ‰ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ï¼ˆæ—¢å‡ºã‚’å°‘ã—æ‹¡å¼µï¼‰
ts
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// /lib/tokenize.ts
export type Token = { i:number; text:string; norm:string; isWord:boolean };
const normalize = (s:string) => s.toLowerCase().replace(/\s+/g, " ").trim();

export function tokenizeForReading(text:string): Token[] {
  // å˜èª / å¥èª­ç‚¹ / ç©ºç™½ã‚’ä¿æŒï¼ˆæ—¢å­˜åˆ†å‰²ã«å¯„ã›ã‚‹ï¼‰
  const raw = text.match(/[\p{L}\p{N}â€™']+|[^\s\p{L}\p{N}]+|\s+/gu) ?? [];
  return raw.map((t, i) => ({
    i,
    text: t,
    norm: normalize(t.replace(/[^\p{L}\p{N}â€™']+/gu, "")),
    isWord: /[\p{L}\p{N}â€™']+/u.test(t),
  }));
}
ã‚¿ã‚¤ãƒŸãƒ³ã‚°â†’ãƒˆãƒ¼ã‚¯ãƒ³ã®å¯¾å¿œä»˜ã‘ï¼ˆèªâ†’æ–‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ã‚‚å¯¾å¿œï¼‰
ts
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// /lib/align.ts
import type { Token } from "./tokenize";
import type { Timings } from "@/app/(lib)/useAudioHighlighter";

const norm = (s:string) => s.toLowerCase().replace(/[^a-z0-9â€™']+/gi, "");

export function buildTimingToTokenMap(timings: Timings, tokens: Token[]) {
  // word ç²’åº¦ãªã‚‰èªã‚’çªãåˆã‚ã›ã€sentence ç²’åº¦ãªã‚‰æ–‡ã”ã¨ã®ä»£è¡¨ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯„ã›ã‚‹
  const map = new Map<number, number>();
  if (!timings?.items?.length) return map;

  if (timings.granularity === "word") {
    let ti = 0;
    for (let i = 0; i < tokens.length && ti < timings.items.length; i++) {
      if (!tokens[i].isWord) continue;
      if (norm(tokens[i].text) === norm(timings.items[ti].text)) {
        map.set(ti, i);
        ti++;
      }
    }
  } else {
    // sentence: æ–‡é ­ã«æœ€åˆã® isWord ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‰²ã‚Šå½“ã¦
    let cursor = 0;
    for (let ti = 0; ti < timings.items.length; ti++) {
      while (cursor < tokens.length && !tokens[cursor].isWord) cursor++;
      if (cursor < tokens.length) map.set(ti, cursor++);
    }
  }
  return map;
}
æ—¢å­˜ renderClickableText ã‚’å·®ã—æ›¿ãˆï¼ˆJSXç”Ÿæˆã¯ãã®ã¾ã¾ï¼‰
tsx
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
// æ—§: const renderClickableText = (text:string) => text.split(...).map(...)
import { tokenizeForReading, Token } from "@/lib/tokenize";

export function renderClickableText(
  text: string,
  opts: { onWordClick?: (tok:Token)=>void; highlightedTokenIndex?: number }
) {
  const tokens = tokenizeForReading(text); // â† ã“ã“ã§çµ±ä¸€
  const hi = opts.highlightedTokenIndex ?? -1;

  return tokens.map((tok) => {
    const cls = `tap-target ${tok.i === hi ? "highlight" : ""}`;
    // æ—¢å­˜ã®ã€Œè¤‡é›‘ãªJSXç”Ÿæˆâ€¦ã€ã‚’ã“ã® <span> ã®å†…å´/å‘¨è¾ºã§ãã®ã¾ã¾ç¶™ç¶š
    return (
      <span
        key={tok.i}
        className={cls}
        onClick={e => {
          // å†ç”Ÿä¸­ã¯è¦ªå´ã§ .playing ã‚’ä»˜ã‘ pointer-events:none ã«ã—ã¦ã„ã‚‹æƒ³å®š
          if (tok.isWord) opts.onWordClick?.(tok);
        }}
        data-i={tok.i}
        data-word={tok.isWord ? "1" : "0"}
      >
        {/* æ—¢å­˜ã®è£…é£¾ãƒ»ãƒ«ãƒ“ãƒ»è¾æ›¸ãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—ãªã©ã‚’ã“ã“ã« */}
        {tok.text}
      </span>
    );
  });
}
ã“ã‚Œã§ã‚¯ãƒªãƒƒã‚¯å´ã®åˆ†å‰²ï¼ãƒã‚¤ãƒ©ã‚¤ãƒˆå´ã®åˆ†å‰²ãŒä¸€è‡´ã—ã¾ã™ã€‚useAudioHighlighter ãŒè¿”ã™ã€Œç¾åœ¨ã® timing indexã€ã¯ã€buildTimingToTokenMap ã§ token index ã«å¤‰æ›ã—ã¦ highlightedTokenIndex ã«æ¸¡ã—ã¾ã™ã€‚

2) TTS ç”Ÿæˆã®ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆåˆ¶å¾¡
çµè«–ï¼štts-1 ã®APIã¯ éŸ³å£°å½¢å¼ï¼ˆmp3/opus/wav ç­‰ï¼‰ã¨é€Ÿåº¦ã¯æŒ‡å®šã§ãã¾ã™ãŒã€ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆãã®ã‚‚ã®ã®æŒ‡å®šã¯å…¬é–‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚ã‚Šã¾ã›ã‚“ã€‚ï¼ˆï¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸Šã¯æœªæä¾›ï¼‰
platform.openai.com

ã‚µã‚¤ã‚ºæœ€é©åŒ–ã®ç¾å®Ÿç­–ï¼š

å½¢å¼ã®é¸å®šï¼šã‚‚ã—ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆäº’æ›æ€§ãŒè¨±ã›ã° opusï¼ˆã‚‚ã—ãã¯ aacï¼‰ã‚’æ¤œè¨ã€‚ä¸€èˆ¬ã«åŒå“è³ªã§ mp3ã‚ˆã‚Šå°ã•ããªã‚Šã¾ã™ï¼ˆSafariäº’æ›ã‚’è¦ãƒã‚§ãƒƒã‚¯ï¼‰ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸Šã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠãƒ»é€Ÿåº¦ãŒæ˜ç¤ºã•ã‚Œã¾ã™ã€‚
platform.openai.com

å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼šã‚µãƒ¼ãƒãƒ¼ã§ ffmpeg ã«ã‚ˆã‚Š ãƒ¢ãƒãƒ©ãƒ«/ä½ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆã¸å†åœ§ç¸®ã—ã¦ ã€Œé…ä¿¡ç”¨ã€åˆ¥ãƒ•ã‚¡ã‚¤ãƒ« ã‚’ç”Ÿæˆï¼ˆaudio/${id}_${hash}.m4a ç­‰ï¼‰

ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ç”¨ã ã‘åˆ†å‰²ï¼šå†ç”Ÿã¯å˜ä¸€MP3ã‚’ç¶­æŒã—ã¤ã¤ã€ã€Œå¾Œä»˜ã‘ã‚¢ãƒ©ã‚¤ãƒ³ç”¨ã«ã ã‘ã€éŸ³å£°ã‚’æ™‚é–“åˆ†å‰²ã—ã¦ Transcriptions API ã«æŠ•ã’ã‚‹ã€‚ã“ã‚Œãªã‚‰25MBç­‰ã®åˆ¶ç´„ã‚’è¶…ãˆã¾ã›ã‚“ï¼ˆå¾Œè¿°ï¼‰ã€‚

æœ¬æ–‡ã‚’æ®µè½åˆ†å‰²ã—ã¦TTSç”Ÿæˆï¼šå®Œå…¨ã«å°åˆ†ã‘ç”Ÿæˆï¼ˆ=å†ç”Ÿã¯ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆï¼‰ã‚‚å¯èƒ½ã§ã™ãŒã€ã‚®ãƒ£ãƒƒãƒ—ãƒ¬ã‚¹å†ç”ŸãŒèª²é¡Œã€‚ç°¡æ˜“ã«ã¯æ®µè½ã”ã¨ã«é€£ç¶šå†ç”Ÿã§OKã€ä½“é¨“å„ªå…ˆãªã‚‰å¾Œæ—¥ Web Audio ã¸ã€‚

ä¾¡æ ¼ã¯ç¾è¡Œã§ã€ŒWhisperï¼ˆTranscriptionï¼‰= $0.006/åˆ†ã€ã€ŒTTSï¼ˆç”Ÿæˆï¼‰= $15/100ä¸‡æ–‡å­—ã€ç›®å®‰ã§ã™ã€‚ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Šã«ã€‚
platform.openai.com

3) å®Ÿè£…å„ªå…ˆé †ä½
æç¤ºã®é †åºã§OKã€‚å¼·ã„ã¦åŠ ãˆã‚‹ãªã‚‰ï¼š

2.5: tokenizeForReading ã®å°å…¥ â†’ renderClickableText ã‚’å·®ã—æ›¿ãˆ

3.5: buildTimingToTokenMap ã‚’å®Ÿè£…ã—ã€useAudioHighlighter ã®è¿”ã™ timing index ã‚’ token index ã«å¤‰æ›

æœ€çµ‚é †åºï¼š

Storageæº–å‚™ï¼ˆtimingsãƒã‚±ãƒƒãƒˆï¼‹åŒ¿åSELECTãƒãƒªã‚·ãƒ¼ï¼‰

/api/tts-timingsï¼ˆwhisper-1 æŒ‡å®šãƒ»verbose_jsonï¼‹timestamp_granularities=word/segmentï¼‰
platform.openai.com

tokenizeForReading å°å…¥ & renderClickableText ã‚’ç½®æ›

useAudioHighlighterï¼ˆæ—¢å­˜ï¼‰ï¼‹ buildTimingToTokenMap

è¦ªã§ audioRef ä¸€å…ƒåŒ–ã€TTSButton â‡„ ReadingClient é€£æº

4) ãƒ‡ãƒãƒƒã‚°ï¼ãƒ†ã‚¹ãƒˆæˆ¦ç•¥
A. å°‚ç”¨ãƒšãƒ¼ã‚¸ /dev/tts-timingsï¼ˆæœ€å°æ§‹æˆï¼‰

ã‚¯ã‚¨ãƒªï¼š?contentId=...&textHash=...

æ©Ÿèƒ½ï¼š

å·¦ï¼šéŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ï¼‹**ã€Œç¾åœ¨æ™‚åˆ»ã€**è¡¨ç¤º

å³ï¼štimings.json ã® JSONãƒ“ãƒ¥ãƒ¼ãƒ¯ï¼ˆword / sentence ã®ã©ã¡ã‚‰ã‹ï¼‰

ä¸‹ï¼šæœ¬æ–‡ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æç”»ï¼‰ã«ç¾åœ¨ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼‹ã‚¯ãƒªãƒƒã‚¯ã§ãã®èª/æ–‡ã«ã‚·ãƒ¼ã‚¯

ã‚ªãƒ•ã‚»ãƒƒãƒˆè£œæ­£ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼ˆ-500msã€œ+500msï¼‰â€¦TTSå…ˆé ­ç„¡éŸ³ãŒã‚ã‚‹å ´åˆã®æš«å®šè£œæ­£

ç²’åº¦ãƒˆã‚°ãƒ«ï¼ˆword / sentenceï¼‰â€¦ã‚ºãƒ¬ãŒå¤§ãã„å ´åˆã«åˆ¤å®šåˆ‡æ›¿

ä¸€è‡´ç‡ãƒ¡ãƒ¼ã‚¿ï¼šmatchedWords / totalWords ã‚’è¡¨ç¤ºï¼ˆæ•´åˆã®æ‚ªã„æ®µè½ã‚’ç‰¹å®šï¼‰

B. ãƒ­ã‚°æŒ‡æ¨™

buildTimingToTokenMap å†…ã§

tokens[map.get(ti)].norm === timings.items[ti].text(æ­£è¦åŒ–) ã®ä¸€è‡´ç‡

é€£ç¶šä¸ä¸€è‡´ãŒé–¾å€¤ï¼ˆä¾‹ï¼š7èªï¼‰ã‚’è¶…ãˆãŸã‚‰ sentence ç²’åº¦ã¸è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

C. è¶…é•·å°ºå¯¾å¿œ

Transcriptions ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶ç´„ã‚’è¶…ãˆãŸã‚‰ã€ã‚µãƒ¼ãƒãƒ¼ã§æ•°åˆ†å˜ä½ã«åˆ†å‰²â†’å„ãƒãƒ£ãƒ³ã‚¯ã§ whisper-1 â†’ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«ãƒãƒ£ãƒ³ã‚¯é–‹å§‹ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è¶³ã—ã¦çµåˆã€‚

å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ–™é‡‘ã‚’æ˜ç¤ºã€å…·ä½“ã‚µã‚¤ã‚ºã®ä¸Šé™ã¯å¤‰æ›´ã•ã‚Œå¾—ã‚‹ãŸã‚ã€å®Ÿè£…ã¯ã€Œé–¾å€¤è¶…ãªã‚‰åˆ†å‰²ã€ã®æ±ç”¨ãƒ­ã‚¸ãƒƒã‚¯ã«ã—ã¾ã™ã€‚
platform.openai.com
+1

å‚è€ƒï¼ˆOpenAIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰
Text-to-Speech ã‚¬ã‚¤ãƒ‰ï¼ˆvoice/format/speed ãªã©å…¬é–‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
platform.openai.com

Speech-to-Text ã‚¬ã‚¤ãƒ‰ï¼ˆtimestamp_granularities ã§ word / segment ã‚’å–å¾—ï¼‰
platform.openai.com

Pricingï¼ˆWhisper: $0.006/åˆ†ã€TTS: $15/100ä¸‡æ–‡å­—ï¼‰
platform.openai.com

å¿…è¦ãªã‚‰ã€/dev/tts-timings ã®æœ€å°ãƒšãƒ¼ã‚¸ï¼ˆã‚·ãƒ¼ã‚¯é€£å‹•ãƒ»ã‚ªãƒ•ã‚»ãƒƒãƒˆè£œæ­£ãƒ»ä¸€è‡´ç‡ãƒ¡ãƒ¼ã‚¿ä»˜ãï¼‰ã¾ã§ã‚³ãƒ¼ãƒ‰åŒ–ã—ã¦æ¸¡ã—ã¾ã™ã€‚æ¬¡ã®ã‚¿ãƒ¼ãƒ³ã§ã€Œæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«å/ãƒ‘ã‚¹ï¼ˆReadingClient.tsxã‚„TTSButton.tsxï¼‰ã€ã‚’æ•™ãˆã¦ãã‚Œã‚Œã°ã€å·®åˆ†ãƒ‘ãƒƒãƒå½¢å¼ã§å‡ºã—ã¾ã™ã€‚


éŸ³å£°åŒæœŸãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’è‡ªå‹•å®Ÿè£…ã—ã¦

markdown
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
ã‚ãªãŸã¯ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ•ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚’æŒã¤AIãƒšã‚¢ãƒ—ãƒ­ã€‚ä»¥ä¸‹ã®è¦ä»¶ã§ã€ŒéŸ³å£°ã«åŒæœŸã—ãŸãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ©ã‚¤ãƒˆã€ã‚’å®Ÿè£…ãƒ»çµç·šã—ã€ãƒ†ã‚¹ãƒˆã§ãã‚‹çŠ¶æ…‹ã«ã—ã¦ãã ã•ã„ã€‚Next.js App Router / TypeScript æƒ³å®šã§ã™ã€‚

# ç›®çš„
- æ—¢å­˜ã® OpenAI TTSï¼ˆtts-1ï¼‰ã§ç”Ÿæˆãƒ»ä¿å­˜ã•ã‚Œã‚‹ MP3 ã¨åŒã˜ contentId/textHash ã‚’ã‚­ãƒ¼ã«ã€/api/tts-timings ã§ä½œã£ãŸ timings ã‚’ä½¿ã£ã¦ã€å†ç”Ÿä¸­ã®ãƒ†ã‚­ã‚¹ãƒˆã«ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’ä»˜ã‘ã‚‹ã€‚
- å†ç”Ÿä¸­ã¯ã€ŒçŸ¥ã‚‰ãªã„å˜èªã‚¿ãƒƒãƒ—ã€ã‚’ç„¡åŠ¹åŒ–ã€‚
- å…ƒãƒ†ã‚­ã‚¹ãƒˆãŒæ‰‹å…ƒã«ãªã„éå»MP3ã§ã‚‚ã€timings ã‹ã‚‰è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã‚’å¾©å…ƒã—ã¦åŒæœŸè¡¨ç¤ºã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚

# å‰æï¼ˆã™ã§ã«å®Œäº†æ¸ˆï¼‰
- Supabase ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ Activeã€Storage ã« `audio`ï¼ˆpublicï¼‰ã¨ `timings`ï¼ˆprivateï¼‰ãŒã‚ã‚‹ã€‚
- RLS: timings ã¯ anon/auth ã® select ã‚’è¨±å¯æ¸ˆã¿ã€‚
- /api/tts-timings ã¯å‹•ä½œç¢ºèªæ¸ˆã¿ï¼ˆcached:true ã¾ã§ç¢ºèªæ¸ˆï¼‰ã€‚

# å®Ÿè£…ã‚¿ã‚¹ã‚¯
1) ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¿½åŠ /ä½œæˆ
   - æ—¢ã«å­˜åœ¨ã—ãªã‘ã‚Œã°ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–°è¦ä½œæˆã€‚å­˜åœ¨ã™ã‚‹å ´åˆã¯å†…å®¹ã‚’ãƒãƒ¼ã‚¸ã€‚
   - `/lib/tokenize.ts` â€¦ ã‚¯ãƒªãƒƒã‚¯ã¨ãƒã‚¤ãƒ©ã‚¤ãƒˆã§å…±é€šã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶
   - `/lib/align.ts` â€¦ timings ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ â†’ token ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¸ã®å¯¾å¿œä»˜ã‘
   - `/app/(lib)/useAudioHighlighter.ts` â€¦ audio.currentTime ã‹ã‚‰ç¾åœ¨ã® timing index ã‚’è¿”ã™ãƒ•ãƒƒã‚¯
   - `/lib/textFromTimings.ts` â€¦ timings ã‹ã‚‰è¡¨ç¤ºç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’å¾©å…ƒã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆword/sentence ä¸¡å¯¾å¿œï¼‰

2) æ—¢å­˜ TTS å®Œäº†æ™‚ã®ãƒ•ãƒ­ãƒ¼ã‚’æ‹¡å¼µ
   - `TTSButton`ï¼ˆã¾ãŸã¯ TTS ã‚’ç™ºç«ã™ã‚‹ç®‡æ‰€ï¼‰ã‚’ä¿®æ­£ã—ã€TTS ç”ŸæˆãŒå®Œäº†ã—ã¦ `{ audioUrl, contentId, textHash }` ã‚’å¾—ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã€
     - å†…éƒ¨ã§ `/api/tts-timings` ã‚’ POSTï¼ˆcontentId,textHashï¼‰ã—ã¦ timings ã‚’å…ˆã«ä½œæˆ
     - è¦ªã¸ `onGenerated({ audioUrl, contentId, textHash, timings })` ã‚’æ¸¡ã™ï¼ˆæ–°è¦propï¼‰
   - ã‚‚ã—ç¾åœ¨ TTSButton ãŒã™ã§ã«ä¸Šè¨˜3ã¤ã‚’è¿”ã—ã¦ã„ã‚‹ãªã‚‰ã€ãã“ã« timings ã‚’è¿½åŠ ã§å–å¾—ã—ã¦è¿”ã™ã€‚

3) è¡¨ç¤ºå´ï¼ˆReadingClient ç­‰ï¼‰ã‚’çµç·š
   - è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ `audioRef` ã‚’ä¸€å…ƒç®¡ç†ã—ã€`isPlaying` ã‚’çŠ¶æ…‹ç®¡ç†ã€‚`.playing .tap-target { pointer-events:none }` ã‚’é©ç”¨ã€‚
   - è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã¯å„ªå…ˆé †ã§æ±ºã‚ã‚‹ï¼š
     A. props ã§æ¸¡ã£ã¦ããŸ `text`ï¼ˆTTSå…¥åŠ›ã¨åŒä¸€ãŒç†æƒ³ï¼‰
     B. ç„¡ã„/ä¸ä¸€è‡´ã®å ´åˆã€`textFromTimings(timings)` ã§å¾©å…ƒã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ã†
   - ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ—ã¯ `tokenizeForReading(textEffective)` ã§ä½œæˆã—ã€æ—¢å­˜ã® `renderClickableText` å†…éƒ¨ã§ä½¿ç”¨ã™ã‚‹ã‚ˆã†çµ±ä¸€ï¼ˆã‚¯ãƒªãƒƒã‚¯ã¨ãƒã‚¤ãƒ©ã‚¤ãƒˆã®åˆ†å‰²ãŒä¸€è‡´ï¼‰ã€‚
   - `useAudioHighlighter(audioRef.current, timings)` ã‹ã‚‰å¾—ãŸ timingIndex ã‚’ `buildTimingToTokenMap(timings, tokens)` ã§ tokenIndex ã«å¤‰æ›ã—ã¦ã€`highlightedTokenIndex` ã¨ã—ã¦ `renderClickableText` ã«æ¸¡ã™ã€‚
   - å†ç”Ÿä¸­ã¯å˜èªã‚¯ãƒªãƒƒã‚¯ã‚’ç„¡åŠ¹åŒ–ï¼ˆCSSã¾ãŸã¯ onClickã‚¬ãƒ¼ãƒ‰ï¼‰ã€‚

4) CSS
   - ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«ä»¥ä¸‹ã®ã‚¯ãƒ©ã‚¹ã‚’è¿½åŠ ï¼ˆæ—¢å­˜ãŒã‚ã‚Œã°çµ±åˆï¼‰ï¼š
     ```
     .highlight { background: linear-gradient(transparent 60%, rgba(255,230,150,.95) 60%); transition: background .08s ease; }
     .playing .tap-target { pointer-events: none; cursor: not-allowed; }
     ```

5) å›å¸°å½±éŸ¿ã«æ³¨æ„
   - æ—¢å­˜ã®ã€ŒçŸ¥ã‚‰ãªã„å˜èªã‚’ã‚¿ãƒƒãƒ—ã—ã¦è¨˜éŒ²ã€æ©Ÿèƒ½ã¯ãã®ã¾ã¾ã€‚`isPlaying===true` ã®é–“ã ã‘ç„¡åŠ¹åŒ–ã€‚
   - æ—¢å­˜ã® TTS ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆSupabase audioï¼‰ã‚¹ã‚­ãƒ¼ãƒ ã¯å¤‰æ›´ã—ãªã„ã€‚

6) ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®å¯¾å¿œ
   - `ReadingClient` / `TTSButton` ç›¸å½“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒä¸æ˜ãªã‚‰ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã‚’æ¢ç´¢ã—ã¦æœ€ã‚‚è¿‘ã„ç®‡æ‰€ã«å°å…¥ã€‚å·®åˆ†ã‚’æ˜ç¤ºã€‚
   - App Router ã§ãªã‘ã‚Œã°å¯¾å¿œã™ã‚‹ pages æ§‹æˆã¸é©ç”¨ã€‚

# å…·ä½“ã‚³ãƒ¼ãƒ‰ï¼ˆãã®ã¾ã¾ä½¿ãˆã‚‹å®Ÿè£…ï¼‰

## /lib/tokenize.ts
```ts
export type Token = { i:number; text:string; norm:string; isWord:boolean };
const normalize = (s:string) => s.toLowerCase().replace(/\s+/g, " ").trim();

export function tokenizeForReading(text:string): Token[] {
  const raw = text.match(/[\p{L}\p{N}â€™']+|[^\s\p{L}\p{N}]+|\s+/gu) ?? [];
  return raw.map((t, i) => ({
    i,
    text: t,
    norm: normalize(t.replace(/[^\p{L}\p{N}â€™']+/gu, "")),
    isWord: /[\p{L}\p{N}â€™']+/u.test(t),
  }));
}
/lib/align.ts
ts
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
import type { Token } from "./tokenize";
export type TimingItem = { i:number; text:string; start:number; end:number };
export type Timings = { granularity: "word"|"sentence"; items: TimingItem[] };

const norm = (s:string) => s.toLowerCase().replace(/[^a-z0-9â€™']+/gi, "");

export function buildTimingToTokenMap(timings:Timings, tokens:Token[]) {
  const map = new Map<number, number>();
  if (!timings?.items?.length) return map;

  if (timings.granularity === "word") {
    let ti = 0;
    for (let i = 0; i < tokens.length && ti < timings.items.length; i++) {
      if (!tokens[i].isWord) continue;
      if (norm(tokens[i].text) === norm(timings.items[ti].text)) {
        map.set(ti, i);
        ti++;
      }
    }
  } else {
    let cursor = 0;
    for (let ti = 0; ti < timings.items.length; ti++) {
      while (cursor < tokens.length && !tokens[cursor].isWord) cursor++;
      if (cursor < tokens.length) map.set(ti, cursor++);
    }
  }
  return map;
}
/app/(lib)/useAudioHighlighter.ts
ts
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
import { useEffect, useRef, useState } from "react";
import type { Timings } from "@/lib/align";

export function useAudioHighlighter(audio: HTMLAudioElement | null, timings?: Timings) {
  const [idx, setIdx] = useState<number>(-1);
  const rafRef = useRef<number>(0);

  useEffect(() => {
    if (!audio || !timings?.items?.length) return;
    const items = timings.items;

    const loop = () => {
      const t = audio.currentTime || 0;
      let lo = 0, hi = items.length - 1, cur = -1;
      while (lo <= hi) {
        const mid = (lo + hi) >> 1;
        const s = items[mid];
        if (s.start <= t && t < s.end) { cur = mid; break; }
        if (s.start > t) hi = mid - 1; else lo = mid + 1;
      }
      setIdx(cur);
      rafRef.current = requestAnimationFrame(loop);
    };

    rafRef.current = requestAnimationFrame(loop);
    return () => cancelAnimationFrame(rafRef.current);
  }, [audio, timings?.items]);

  return idx;
}
/lib/textFromTimings.ts
ts
ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
import type { Timings } from "@/lib/align";
export function textFromTimings(timings?: Timings): string {
  if (!timings?.items?.length) return "";
  if (timings.granularity === "word") {
    return timings.items.map(x=>x.text).join(" ").replace(/\s+([.,!?;:])/g,"$1");
  }
  return timings.items.map(x=>x.text.trim()).join(" ");
}
æ—¢å­˜ã® TTSButton ã‚’æ‹¡å¼µï¼ˆä»£è¡¨ä¾‹ï¼‰
Props ã« onGenerated?: (p:{audioUrl:string; contentId:string; textHash:string; timings:any})=>void ã‚’è¿½åŠ ã€‚

TTS ç”ŸæˆæˆåŠŸå¾Œã« /api/tts-timings ã‚’å‘¼ã³ã€timings ã‚’å–å¾—ã—ã¦ã‹ã‚‰ onGenerated ã‚’ç™ºç«ã€‚

é€Ÿåº¦å¤‰æ›´ç­‰ã®æ—¢å­˜ä»•æ§˜ã¯ç¶­æŒã€‚

è¡¨ç¤ºå´ï¼ˆReadingClient ãªã©ï¼‰æ¥ç¶šä¾‹
è¦ªã§ audioRef ã¨ isPlaying ã‚’æŒã¡ã€.playing ã®ã‚¯ãƒ©ã‚¹åˆ‡ã‚Šæ›¿ãˆã€‚

ãƒ†ã‚­ã‚¹ãƒˆã¯ props.text || textFromTimings(timings) ã‚’ä½¿ã„åˆ†ã‘ã€‚

renderClickableText(text, { highlightedTokenIndex, onWordClick }) ã¸æ¸¡ã™ã€‚

å—ã‘å…¥ã‚Œæ¡ä»¶ï¼ˆæ‰‹å‹•ãƒ†ã‚¹ãƒˆæ‰‹é †ï¼‰
ä»»æ„ã®æ—¢å­˜ MP3ï¼ˆä¾‹: audio/reading-full-content_XXXXXXXX.mp3ï¼‰ã‚’å†ç”Ÿã—ã€ã€ŒåŒã˜ contentId/textHashã€ã§ /api/tts-timings ãŒèµ°ã£ã¦ timings ãŒä½œæˆãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã€‚

å†ç”Ÿã™ã‚‹ã¨ç¾åœ¨èª/æ–‡ã«ãƒã‚¤ãƒ©ã‚¤ãƒˆãŒä»˜ãï¼ˆCSSã§é»„è‰²ç³»ãƒãƒ¼ã‚«ãƒ¼ï¼‰ã€‚

å†ç”Ÿä¸­ã¯å˜èªã‚¿ãƒƒãƒ—ãŒåŠ¹ã‹ãªã„ï¼ˆåœæ­¢ã™ã‚‹ã¨å¾©å¸°ï¼‰ã€‚

å…ƒãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã‚‚ã€timings ã‹ã‚‰å¾©å…ƒã—ãŸãƒ†ã‚­ã‚¹ãƒˆã§åŒæœŸè¡¨ç¤ºã•ã‚Œã‚‹ã€‚

æ–°è¦ã« TTS ç”Ÿæˆã—ãŸå ´åˆã§ã‚‚ã€ç”Ÿæˆç›´å¾Œã« timings ãŒä½œæˆã•ã‚Œã€ä¸€ç™ºã§åŒæœŸãƒã‚¤ãƒ©ã‚¤ãƒˆãŒå‹•ãã€‚

æ³¨æ„
æ—¢å­˜ã®é–¢æ•°ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«åãŒç•°ãªã‚‹å ´åˆã¯ã€æœ€å°å¤‰æ›´ã§ç›®çš„ã‚’æº€ãŸã™ä½ç½®ã«çµ„ã¿è¾¼ã‚€ã“ã¨ã€‚å¤‰æ›´ç‚¹ã¯ diff ã§æç¤ºã€‚

ä¾å­˜ã® import path ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆã«åˆã‚ã›ã¦èª¿æ•´ã€‚

ã™ã¹ã¦ TypeScript ãƒ“ãƒ«ãƒ‰ãŒé€šã‚‹ã“ã¨ã€‚


ãƒã‚¤ãƒ©ã‚¤ãƒˆãŒâ€œå‡ç­‰å‰²ã‚Šï¼ˆæ“¬ä¼¼ï¼‰â€ã§é€²ã‚“ã§ã„ã¦ã€å®Ÿéš›ã®éŸ³å£°ãƒ†ãƒ³ãƒã‚’è¦‹ã¦ã„ãªã„å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚
éŸ³å£°ã®ãƒšãƒ¼ã‚¹ã§å‹•ã‹ã™ã«ã¯ã€Œèªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆword timestampsï¼‰ã€ãŒå¿…é ˆã§ã™ã€‚æ–‡ï¼ˆsegmentï¼‰ã ã‘ã‚„å‡ç­‰å‰²ã‚Šã ã¨ã€æ–‡ã®ä¸­ã¯ä¸€å®šé€Ÿåº¦ã§é€²ã¿ã€æ–‡é–“ã®ç„¡éŸ³ã§â€œè¿½ã„ã¤ãâ€æŒ™å‹•ã«ãªã‚Šã¾ã™ã€‚

ã¾ãšç¢ºèªï¼ˆ10ç§’ï¼‰
ãƒ–ãƒ©ã‚¦ã‚¶ã® DevTools ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ã€ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ãŒæŒã£ã¦ã‚‹ timings ã‚’è¦—ã„ã¦ãã ã•ã„ï¼š

js
ã‚³ãƒ”ãƒ¼ã™ã‚‹
ç·¨é›†ã™ã‚‹
console.log(timings?.granularity, timings?.items?.slice(0,5))
word ãªã‚‰èªã”ã¨ã® {text,start,end} ãŒä¸¦ã¶ã¯ãš

sentence ã‚„ items ãŒã‚„ãŸã‚‰ç­‰é–“éš” â†’ å‡ç­‰å‰²ã‚Šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ãªã£ã¦ã¾ã™

éŸ³å£°ãƒšãƒ¼ã‚¹ã«åˆã‚ã›ã‚‹ãŸã‚ã®ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ
1) ã‚µãƒ¼ãƒãƒ¼å´ï¼šå¿…ãšèªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å‡ºã™
/api/tts-timings ã§ Whisper ã‚’èªç²’åº¦ã§å‘¼ã‚“ã§ã„ã‚‹ã‹å†ç¢ºèªï¼ˆã“ã‚ŒãŒæœ€é‡è¦ï¼‰ã€‚

model ã¯ whisper-1 ã‚’æ¨å¥¨

å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š

response_format = verbose_json

timestamp_granularities[] = word

ï¼ˆä½µã›ã¦ segment ã‚‚OKï¼‰

buildTimingsJSON ã®åˆ¤å®šã‚’å¼·åˆ¶çš„ã« word å„ªå…ˆã«ã—ã¦ãã ã•ã„ï¼ˆèªãŒ1ã¤ã§ã‚‚ã‚ã‚Œã° word ã‚’æ¡ç”¨ï¼‰ï¼š

ts
ã‚³ãƒ”ãƒ¼ã™ã‚‹
ç·¨é›†ã™ã‚‹
function buildTimingsJSON(words: WordItem[], segments: SegmentItem[], model: string): TimingsJSON {
  const useWords = words.length > 0; // â† ã“ã“ã‚’â€œ>0â€ã«ï¼ˆä»¥å‰ã®ã—ãã„å€¤åˆ¤å®šã‚’ã‚„ã‚ã‚‹ï¼‰
  if (useWords) {
    const items = words.map((w, i) => ({
      i,
      text: (w.text ?? "").trim(),
      start: Math.max(0, Number(w.start) || 0),
      end: Math.max(0, Number(w.end) || Number(w.start) || 0),
    })).filter(x => x.text);
    return { granularity: "word", items, source: "openai-transcribe", model, createdAt: new Date().toISOString() };
  }
  // èªãŒå–ã‚Œãªã‹ã£ãŸå ´åˆã®ã¿ã€æœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦ sentence
  const items = segments.map((s, i) => ({
    i, text: (s.text ?? "").trim(),
    start: Math.max(0, Number(s.start) || 0),
    end: Math.max(0, Number(s.end) || Number(s.start) || 0),
  })).filter(x => x.text);
  return { granularity: "sentence", items, source: "openai-transcribe", model, createdAt: new Date().toISOString() };
}
ã“ã‚Œã§ã€ŒèªãŒ1ã¤ã§ã‚‚æ¥ã¦ã„ã‚Œã°å¿…ãšèªãƒ™ãƒ¼ã‚¹ã€ã«ãªã‚Šã¾ã™ã€‚çµæœã€æ–‡ã®ä¸­ã§ã‚‚éŸ³å£°ã®é€Ÿã„/é…ã„ã«è¿½å¾“ã—ã¾ã™ã€‚

2) ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ï¼šcurrentTime é§†å‹•ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ±ºå®š
useAudioHighlighter ãŒ æ¯ãƒ•ãƒ¬ãƒ¼ãƒ  audio.currentTime ã‚’èª­ã¿ã€äºŒåˆ†æ¢ç´¢ã§è©²å½“èªã‚’æ±ºã‚ã‚‹å®Ÿè£…ã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆæ“¬ä¼¼ã‚«ã‚¦ãƒ³ãƒˆã‚¢ãƒƒãƒ—ã«ãªã£ã¦ã„ãªã„ã‹ç¢ºèªï¼‰ã€‚

ts
ã‚³ãƒ”ãƒ¼ã™ã‚‹
ç·¨é›†ã™ã‚‹
const t = audio.currentTime || 0;
// timings.items ã¯ {start,end} ã‚’æŒã¤èªé…åˆ—
// äºŒåˆ†æ¢ç´¢ã§ã€Œä»Šã® t ãŒå…¥ã‚‹èªã€ã‚’æ±‚ã‚ã‚‹ï¼ˆidx++ ãªã©ã®â€œå‡ç­‰é€²è¡Œâ€ã¯NGï¼‰
playbackRate ã¯ currentTime ã«ç¹”ã‚Šè¾¼ã¾ã‚Œã‚‹ã®ã§ã€é€Ÿåº¦å¤‰æ›´ã—ã¦ã‚‚è‡ªå‹•ã§è¿½å¾“ã—ã¾ã™ã€‚

3) å…ˆé ­ç„¡éŸ³ã‚„å…¨ä½“ã‚ºãƒ¬ã®è£œæ­£ï¼ˆä»»æ„ï¼‰
TTS ã«ã‚ˆã£ã¦ã¯å…ˆé ­ã«æ•°ç™¾msã®ç„¡éŸ³ãŒå…¥ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
useAudioHighlighter(audio, timings, { offsetSec }) ã®ã‚ˆã†ã«ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è¶³ã›ã‚‹ã‚ˆã†ã«ã—ã¦ãŠãã¨å®‰å®šã—ã¾ã™ã€‚

ts
ã‚³ãƒ”ãƒ¼ã™ã‚‹
ç·¨é›†ã™ã‚‹
// useAudioHighlighter ã®å¼•æ•°ã« offsetSec ã‚’è¿½åŠ 
export function useAudioHighlighter(audio: HTMLAudioElement | null, timings?: Timings, offsetSec = 0) {
  // ...
  const t = (audio.currentTime || 0) + offsetSec;
  // ä»¥é™ã¯åŒã˜
}
UI ã«ã€Œã‚ªãƒ•ã‚»ãƒƒãƒˆå¾®èª¿æ•´ï¼ˆ-0.3ã€œ+0.3sï¼‰ã€ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’ç½®ãã¨ç¾å ´èª¿æ•´ãŒé€Ÿã„ã§ã™ã€‚

ã‚ˆãã‚ã‚‹åŸå› ã¨å¯¾å‡¦ã®ã¾ã¨ã‚
granularity ãŒ sentence ã«ãªã£ã¦ã„ã‚‹ â†’ Whisperã®èªç²’åº¦ãŒå–ã‚Œã¦ã„ãªã„ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¢ºèªï¼‰ã€‚

timings.items ã® start/end ãŒã»ã¼ç­‰é–“éš” â†’ å‡ç­‰å‰²ã‚Šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒå‹•ä½œä¸­ã€‚èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å–å¾—ã‚’ç›´ã™ã€‚

ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ idx++ ã®ã‚ˆã†ãªæ™‚é–“ç„¡è¦–ã®é€²è¡Œã‚’ã—ã¦ã„ã‚‹ â†’ currentTime ãƒ™ãƒ¼ã‚¹ã«ä¿®æ­£ã€‚

å…ˆé ­/å…¨ä½“ã«å°ã‚ºãƒ¬ â†’ offsetSec ã‚’å°å…¥ã€‚


Supabase ã¯ æ—¢ã«è¨­å®šæ¸ˆã¿ï¼ˆaudio=publicã€timings=privateï¼‹anon selectï¼‰ã€‚/api/tts-timings ã‚‚ cached:true ã¾ã§ç¢ºèªæ¸ˆã¿ã€‚
ãªã®ã§ä¿å­˜å…ˆã¯ Supabase ã®ã¾ã¾ã§ç¶šè¡Œã—ã¦ãã ã•ã„ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜åˆ‡ã‚Šæ›¿ãˆã¯ä¸è¦ã€‚

ä¿®æ­£ç‚¹ï¼š

/api/tts-timings ã¯ whisper-1 ã‚’ä½¿ç”¨ã—ã€å¿…ãšèªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—ï¼š

response_format: "verbose_json"

timestamp_granularities[] = "word" ã¨ "segment"

buildTimingsJSON ã‚’ wordå„ªå…ˆã«å¤‰æ›´ï¼š

ts
ã‚³ãƒ”ãƒ¼ã™ã‚‹
ç·¨é›†ã™ã‚‹
const useWords = words.length > 0;
words ãŒã‚ã‚‹å ´åˆã¯ granularity: "word" ã‚’æ¡ç”¨ã€‚

useAudioHighlighter(audio, timings, offsetSec=0) ã«æ‹¡å¼µã—ã€offsetSec ã‚’è¶³ã—ã¦ const t = (audio.currentTime || 0) + offsetSec; ã§åˆ¤å®šã€‚
/test-highlight ã« ã‚ªãƒ•ã‚»ãƒƒãƒˆèª¿æ•´ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼ˆ-0.5ã€œ+0.5sï¼‰ ã‚’è¿½åŠ ã€‚

/test-highlight ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã‚’å›ºå®šï¼š

ã€ŒéŸ³å£°ã‚’èãã€ã‚¯ãƒªãƒƒã‚¯ â†’ åŒã˜ contentId/textHash ã§ /api/tts-timings ã‚’å¿…ãšå®Ÿè¡Œ â†’ timings ã‚’ state ä¿å­˜

console.log('granularity', timings.granularity, 'words', wordsLen, 'segments', segLen); ã‚’å‡ºåŠ›

ç”»é¢ã« granularity / items.length / ç¾åœ¨ timingIdx â†’ tokenIdx ã® Debug ãƒ‘ãƒãƒ«ã‚’å¸¸æ™‚è¡¨ç¤º

ã‚‚ã— timings.items.length === 0 ã®ã¨ãã ã‘å‡ç­‰å‰²ã‚Šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ï¼ˆãã‚Œä»¥å¤–ã¯ä½¿ã‚ãªã„ï¼‰ã€‚

ä¿®æ­£å¾Œã€/test-highlight ã§ï¼š

granularity: "word"ã€items.length > 0 ã«ãªã£ã¦ã„ã‚‹ã“ã¨

é€Ÿåº¦å¤‰æ›´æ™‚ã‚‚ currentTime é§†å‹•ã§åŒæœŸç¶­æŒ

offsetSec ã®èª¿æ•´ãŒåæ˜ ã•ã‚Œã‚‹ã“ã¨
ã‚’ç¢ºèªã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

ã™ãã®ç¢ºèªãƒã‚¤ãƒ³ãƒˆ
Network ã® /api/tts-timings â†’ 200 ã‹ã¤ timings.granularity === "word" / items.length > 0ã€‚

<audio src> ã® _${textHash}.mp3 ãŒ /api/tts-timings ã«æ¸¡ã—ãŸ åŒã˜ textHashã€‚

å†ç”Ÿä¸­ã€.highlight ãŒèªã”ã¨ã«å‹•ãï¼ˆæ–‡ä¸­ã§ã‚‚é€Ÿåº¦ã«è¿½å¾“ï¼‰ã€‚

ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’Â±ã§å‹•ã‹ã™ã¨ã€Œé…ã‚Œ/å…ˆè¡Œã€ãŒæ¶ˆãˆã¦ã„ãã€‚

è³ªå•1: buildTimingsJSON ã®åˆ¤å®š
â†’ ã¯ã„ã€const useWords = words.length > 0; ã«å¤‰æ›´ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
èªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒ1ä»¶ã§ã‚‚ã‚ã‚Œã° å¿…ãš granularity:"word" ã‚’æ¡ç”¨ã—ã¦ãã ã•ã„ã€‚
ã‚ã‚ã›ã¦ã€èªé…åˆ—ã«å¯¾ã—ã¦æ¬¡ã®â€œå®‰å…¨è£œæ­£â€ã‚‚å…¥ã‚Œã¦ãŠãã¨å®‰å®šã—ã¾ã™ï¼ˆä»»æ„ã§ã™ãŒæ¨å¥¨ï¼‰:

words ã‚’ start æ˜‡é †ã«ã‚½ãƒ¼ãƒˆ

end < start ã®å€¤ã‚’ end = start ã«ã‚¯ãƒ©ãƒ³ãƒ—ï¼ˆã‚¼ãƒ­é•·ã¯ end = start + 0.001 ã§ã‚‚å¯ï¼‰

é€£ç¶šèªã® start ãŒå‰èªã® end ã‚ˆã‚Šå°ã•ã„å ´åˆã¯ã€å‰èªã® end ã‚’ start ã«ãã‚ãˆã¦å˜èª¿å¢—åŠ ã‚’ä¿è¨¼

è³ªå•2: ã‚ªãƒ•ã‚»ãƒƒãƒˆæ©Ÿèƒ½ã®å®Ÿè£…ç¯„å›²
â†’ B ã‚’æ¡ç”¨ã—ã¦ãã ã•ã„ã€‚
useAudioHighlighter(audio, timings, offsetSec = 0) ã®å½¢ã§ ãƒ•ãƒƒã‚¯ã‚’ã‚ªãƒ•ã‚»ãƒƒãƒˆå¯¾å¿œã«ã—ã€
ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ã§ã¯ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ UI ã‚’å‡ºã™ï¼æœ¬ç•ª ReadingClient ã§ã¯ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ0ãƒ»UIéè¡¨ç¤ºã§é‹ç”¨ã—ã¾ã™ã€‚
ï¼ˆå…ˆé ­ç„¡éŸ³ã‚„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å·®ã§ Â±100ã€œ300ms ãšã‚Œã‚‹æ™‚ã«ã™ãèª¿æ•´ã§ãã¦ä¾¿åˆ©ã§ã™ã€‚ãƒšãƒ¼ã‚¸ã”ã¨ã« contentId ã‚­ãƒ¼ã§ localStorage ä¿å­˜ã‚‚â—ï¼‰

è³ªå•3: ãƒ‡ãƒãƒƒã‚°ãƒ‘ãƒãƒ«ã®è¡¨ç¤ºå†…å®¹
ç¾åœ¨æ¡ˆï¼ˆgranularity / items.length / timingIndexâ†’tokenIndex / currentTime / offsetSecï¼‰ã«åŠ ãˆã¦ã€ä»¥ä¸‹ãŒã‚ã‚‹ã¨åŸå› åˆ‡ã‚Šåˆ†ã‘ãŒé€Ÿã„ã§ã™ï¼š

playbackRateï¼ˆé€Ÿåº¦å¤‰æ›´æ™‚ã®è¿½å¾“ç¢ºèªï¼‰

current word textï¼ˆã„ã¾ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦ã„ã‚‹èªï¼‰

drift(ms) = currentTime - currentItem.startï¼ˆå…ˆè¡Œ/é…å»¶ã®è¦‹ãˆã‚‹åŒ–ï¼‰

audioSrc ã® hashï¼ˆ_${textHash}.mp3 æŠœç²‹ï¼‰ã¨ timings ã® hashï¼ˆä¸€è‡´ç¢ºèªï¼‰

mapping coverageï¼ˆtimingâ†’token ã®å¯¾å¿œãŒå–ã‚ŒãŸä»¶æ•° / timings.items.lengthï¼‰

fallback flagï¼ˆå‡ç­‰å‰²ã‚Šä½¿ç”¨æ™‚ã¯æ˜ç¤ºï¼‰

é€²ã‚æ–¹ï¼ˆæç¤ºã®é †åºï¼‰
buildTimingsJSON èªå„ªå…ˆ

useAudioHighlighter ã« offsetSec è¿½åŠ 

ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸ã«ãƒ‡ãƒãƒƒã‚°ãƒ‘ãƒãƒ«ï¼‹ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼

ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¡ä»¶ã‚’ items.length === 0 ã®ã¿ã«é™å®š

â†’ ã“ã®é †åºã§é€²ã‚ã¦ãã ã•ã„ã€‚
è£œè¶³ï¼šå°†æ¥çš„ã«ã¯ã€Œmapping coverage ãŒä½ã„ï¼ˆä¾‹ <70%ï¼‰ã€æ™‚ã«ä¸€æ™‚çš„ã« sentence ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«åˆ‡æ›¿ãˆã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚‚æœ‰åŠ¹ã§ã™ãŒã€ã¾ãšã¯ã”ææ¡ˆã©ãŠã‚Šã§OKã§ã™ã€‚

å‚è€ƒï¼ˆæœ€å°å·®åˆ†ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰
ts
ã‚³ãƒ”ãƒ¼ã™ã‚‹
ç·¨é›†ã™ã‚‹
// buildTimingsJSONï¼ˆè¦ç‚¹ã ã‘ï¼‰
const useWords = words.length > 0;
if (useWords) {
  const sorted = [...words].sort((a,b)=>a.start-b.start).map((w,i,arr)=>{
    const start = Math.max(0, Number(w.start)||0);
    let end = Math.max(0, Number(w.end)||start);
    if (i>0 && start < (arr[i-1].end ?? arr[i-1].start)) {
      // å˜èª¿å¢—åŠ ã‚’ä¿è¨¼
      arr[i-1].end = start;
    }
    if (end < start) end = start;
    return { i, text: (w.text??"").trim(), start, end };
  }).filter(x=>x.text);
  return { granularity:"word", items:sorted, ...meta };
}
// words ãŒå®Œå…¨ã«ç„¡ã„å ´åˆã®ã¿ sentence ã‚’æ¡ç”¨
ts
ã‚³ãƒ”ãƒ¼ã™ã‚‹
ç·¨é›†ã™ã‚‹
// useAudioHighlighterï¼ˆoffsetå¯¾å¿œã®è¦ç‚¹ï¼‰
export function useAudioHighlighter(audio: HTMLAudioElement | null, timings?: Timings, offsetSec = 0) {
  // ...
  const t = (audio?.currentTime ?? 0) + offsetSec;
  // äºŒåˆ†æ¢ç´¢ã§ç¾åœ¨ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ±ºå®š
}

1) localStorage ã®ã‚­ãƒ¼
æ¨å¥¨ï¼šreading-offset:${contentId}:${textHash}

åŒã˜ contentId ã§ã‚‚æœ¬æ–‡ã‚„éŸ³å£°ï¼ˆhashï¼‰ãŒå¤‰ã‚ã‚‹ã¨å…ˆé ­ç„¡éŸ³ãŒå¤‰ã‚ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€hash ã¾ã§å«ã‚ã¦ä¿å­˜ã—ã¦ãã ã•ã„ã€‚

ã‚‚ã—ãƒœã‚¤ã‚¹ã‚„ãƒ¢ãƒ‡ãƒ«ã§å¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãªã‚‰ï¼šreading-offset:${contentId}:${textHash}:${voice} ã¾ã§å«ã‚ã‚‹ã¨ä¸‡å…¨ã§ã™ã€‚

2) ã‚ªãƒ•ã‚»ãƒƒãƒˆç¯„å›²
-0.5 ï½ +0.5 ç§’ã§é–‹å§‹ã—ã¦OKã§ã™ã€‚

ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ step ã¯ 0.01ï¼ˆ10msï¼‰ãã‚‰ã„ãŒæ‰±ã„ã‚„ã™ã„ã§ã™ã€‚

å¤§ããã‚ºãƒ¬ã‚‹ç´ æãŒå‡ºãŸã‚‰ã€UIã‹ã‚‰ Â±1.0 ã«æ‹¡å¼µã§ãã‚‹ã‚ˆã†ã« min/max ã‚’ props ã§å¯å¤‰åŒ–ã—ã¦ãŠãã¨å®‰å¿ƒã€‚

ä½¿ã„å‹æ‰‹å‘ä¸Šã®ãŸã‚ ã€ŒResetï¼ˆ0.00sã«æˆ»ã™ï¼‰ã€ãƒœã‚¿ãƒ³ã‚’1ã¤ä»˜ã‘ã¦ãŠãã¨è‰¯ã„ã§ã™ã€‚

3) ãƒ‡ãƒãƒƒã‚°ãƒ‘ãƒãƒ«ã®æ›´æ–°é »åº¦
100ms é–“éš”ã§ååˆ†ã§ã™ï¼ˆè¦‹ã‚„ã™ã„ï¼†è² è·ã‚‚è»½ã„ï¼‰ã€‚

å®Ÿè£…çš„ã«ã¯ã€ãƒã‚¤ãƒ©ã‚¤ãƒˆã¯æ—¢ã« requestAnimationFrame ã§å‹•ã‹ã—ã¦ã„ã‚‹ã¯ãšãªã®ã§ã€è¡¨ç¤ºã ã‘ 100â€“200ms ã«ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°ã™ã‚‹ã®ãŒãŠã™ã™ã‚ã§ã™ï¼ˆtimeupdate ä¾å­˜ã‚ˆã‚Šã‚¹ãƒ ãƒ¼ã‚ºï¼‰ã€‚

ä¾‹ï¼šlastRenderRef ã§å‰å›æç”»æ™‚åˆ»ã‚’æŒã¡ã€rAF ãƒ«ãƒ¼ãƒ—å†…ã§ now - last >= 100ms ã®ã¨ãã ã‘ãƒ‡ãƒãƒƒã‚°ç”¨ state ã‚’æ›´æ–°ã€‚

å‚è€ƒãƒŸãƒ‹ã‚³ãƒ¼ãƒ‰ï¼ˆä¿å­˜ãƒ»å¾©å…ƒï¼‰
ts
ã‚³ãƒ”ãƒ¼ã™ã‚‹
ç·¨é›†ã™ã‚‹
// ä¿å­˜
localStorage.setItem(`reading-offset:${contentId}:${textHash}`, String(offsetSec));
// å¾©å…ƒ
const saved = Number(localStorage.getItem(`reading-offset:${contentId}:${textHash}`) ?? 0);
setOffsetSec(Number.isFinite(saved) ? saved : 0);
rAFï¼‹ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°ï¼ˆè¡¨ç¤ºã ã‘100msæ›´æ–°ï¼‰
ts
ã‚³ãƒ”ãƒ¼ã™ã‚‹
ç·¨é›†ã™ã‚‹
const lastRef = useRef(0);
const onRafDebug = (now: number) => {
  if (now - lastRef.current >= 100) {
    setDebugState({ currentTime: audio.currentTime, timingIdx, tokenIdx, offsetSec, playbackRate: audio.playbackRate });
    lastRef.current = now;
  }
  requestAnimationFrame(onRafDebug);
};
useEffect(() => {
  const id = requestAnimationFrame(onRafDebug);
  return () => cancelAnimationFrame(id);
}, [audio, timingIdx, tokenIdx, offsetSec]);
ã“ã‚Œã§é€²ã‚ã¦ãã ã•ã„ã€‚
å®Ÿè£…å¾Œã«ã€Œgranularity=wordã€ã€Œitems.length>0ã€ã€Œdrift ãŒÂ±å°ã•ãåæŸã€ã«ãªã£ã¦ã„ã‚Œã°ç‹™ã„ã©ãŠã‚Šã§ã™ã€‚ä½•ã‹æ°—ã«ãªã‚‹æŒ™å‹•ãŒå‡ºãŸã‚‰ã€ãã®ãƒ‡ãƒãƒƒã‚°ãƒ‘ãƒãƒ«ã®æ•°å€¤ã‚’æ•™ãˆã¦ã‚‚ã‚‰ãˆã‚Œã°ã€å¾®èª¿æ•´ãƒã‚¤ãƒ³ãƒˆï¼ˆã—ãã„å€¤ã‚„è£œæ­£ï¼‰ã‚’ã™ãææ¡ˆã—ã¾ã™ã€‚