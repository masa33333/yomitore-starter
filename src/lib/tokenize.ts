import { Token } from '@/types/highlight';

// ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–é–¢æ•°
const normalize = (s: string): string => 
  s.toLowerCase().replace(/\s+/g, ' ').trim();

/**
 * èª­æ›¸ç”¨çµ±ä¸€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶
 * æ—¢å­˜ã®renderClickableTextã®åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯ã«åŸºã¥ã„ã¦å®Ÿè£…
 * å˜èªžã€å¥èª­ç‚¹ã€ç©ºç™½ã‚’å€‹åˆ¥ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦æ‰±ã†
 */
export function tokenizeForReading(text: string): Token[] {
  if (!text || typeof text !== 'string') {
    return [];
  }

  // Unicodeå¯¾å¿œã®æ­£è¦è¡¨ç¾ã§åˆ†å‰²
  // - å˜èªž: æ–‡å­—ãƒ»æ•°å­—ãƒ»ã‚¢ãƒã‚¹ãƒˆãƒ­ãƒ•ã‚£
  // - éžå˜èªž: å¥èª­ç‚¹ãƒ»è¨˜å·
  // - ç©ºç™½: ã‚¹ãƒšãƒ¼ã‚¹ãƒ»ã‚¿ãƒ–ãƒ»æ”¹è¡Œ
  const regex = /[\p{L}\p{N}'']+|[^\s\p{L}\p{N}'']+|\s+/gu;
  const rawTokens = text.match(regex) || [];

  const tokens: Token[] = rawTokens.map((tokenText, i) => {
    // å˜èªžåˆ¤å®šï¼šæ–‡å­—ãƒ»æ•°å­—ãƒ»ã‚¢ãƒã‚¹ãƒˆãƒ­ãƒ•ã‚£ãŒå«ã¾ã‚Œã‚‹ã‹
    const isWord = /[\p{L}\p{N}'']+/u.test(tokenText);
    
    // æ­£è¦åŒ–ï¼šå˜èªžã®ã¿å‡¦ç†ã€éžå˜èªžã¯ç©ºæ–‡å­—
    const normalizedText = isWord 
      ? normalize(tokenText.replace(/[^\p{L}\p{N}'']+/gu, ''))
      : '';

    return {
      i,
      text: tokenText,
      norm: normalizedText,
      isWord,
    };
  });

  console.log('ðŸ”¤ Tokenization result:', {
    originalLength: text.length,
    tokensCount: tokens.length,
    wordsCount: tokens.filter(t => t.isWord).length,
    firstTokens: tokens.slice(0, 5).map(t => ({ text: t.text, isWord: t.isWord }))
  });

  return tokens;
}

/**
 * ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šãƒˆãƒ¼ã‚¯ãƒ³åŒ–çµæžœã®å¯è¦–åŒ–
 */
export function debugTokens(tokens: Token[]): void {
  console.group('ðŸ” Token Debug');
  tokens.forEach((token, index) => {
    console.log(`${index}: ${token.isWord ? 'ðŸ“' : 'âšª'} "${token.text}" (norm: "${token.norm}")`);
  });
  console.groupEnd();
}

/**
 * çµ±è¨ˆæƒ…å ±å–å¾—
 */
export function getTokenStats(tokens: Token[]) {
  const words = tokens.filter(t => t.isWord);
  const punctuation = tokens.filter(t => !t.isWord && !/\s/.test(t.text));
  const whitespace = tokens.filter(t => !t.isWord && /\s/.test(t.text));

  return {
    total: tokens.length,
    words: words.length,
    punctuation: punctuation.length,
    whitespace: whitespace.length,
    avgWordLength: words.length > 0 
      ? words.reduce((sum, t) => sum + t.text.length, 0) / words.length 
      : 0
  };
}